# å®Œæ•´å·¥ä½œæµç¨‹æŒ‡å—

æœ¬æŒ‡å—æä¾›ä»æ•°æ®ç”Ÿæˆåˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

1. [æ•°æ®ç”Ÿæˆé˜¶æ®µ](#æ•°æ®ç”Ÿæˆé˜¶æ®µ)
2. [æ•°æ®å‡†å¤‡å’ŒéªŒè¯](#æ•°æ®å‡†å¤‡å’ŒéªŒè¯)
3. [æ¨¡å‹è®­ç»ƒé˜¶æ®µ](#æ¨¡å‹è®­ç»ƒé˜¶æ®µ)
4. [æ¨¡å‹è¯„ä¼°é˜¶æ®µ](#æ¨¡å‹è¯„ä¼°é˜¶æ®µ)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## æ•°æ®ç”Ÿæˆé˜¶æ®µ

### æ­¥éª¤ 1: ç”Ÿæˆ Dismantleï¼ˆæ‹†è§£ï¼‰æ•°æ®é›†

**ä»»åŠ¡ç›®æ ‡**: æœ€å°åŒ–ç½‘ç»œéŸ§æ€§ï¼Œé€‰æ‹©ç ´åæ€§æœ€å¤§çš„èŠ‚ç‚¹è¿›è¡Œç§»é™¤ã€‚

```bash
# ä»åˆæˆç½‘ç»œç”Ÿæˆ dismantle æ•°æ®
python scripts/generate_data.py \
    --data_source syn \
    --num_graphs 100 \
    --task_type dismantle \
    --budget 10 \
    --output_dir data/fine_tuning/dismantle_syn

# ä»çœŸå®ç½‘ç»œç”Ÿæˆ dismantle æ•°æ®
python scripts/generate_data.py \
    --data_source true \
    --num_graphs 50 \
    --task_type dismantle \
    --budget 10 \
    --output_dir data/fine_tuning/dismantle_true

# æ··åˆæ•°æ®æº
python scripts/generate_data.py \
    --data_source all \
    --num_graphs 200 \
    --task_type dismantle \
    --budget 10 \
    --output_dir data/fine_tuning/dismantle_all
```

### æ­¥éª¤ 2: ç”Ÿæˆ Constructï¼ˆæ„é€ ï¼‰æ•°æ®é›†

**ä»»åŠ¡ç›®æ ‡**: æœ€å¤§åŒ–ç½‘ç»œéŸ§æ€§ï¼Œé€‰æ‹©å¢ç›Šæœ€å¤§çš„è¾¹è¿›è¡Œæ·»åŠ ã€‚

```bash
# ä»åˆæˆç½‘ç»œç”Ÿæˆ construct æ•°æ®
python scripts/generate_data.py \
    --data_source syn \
    --num_graphs 100 \
    --task_type construct \
    --budget 10 \
    --output_dir data/fine_tuning/construct_syn

# ä»çœŸå®ç½‘ç»œç”Ÿæˆ construct æ•°æ®
python scripts/generate_data.py \
    --data_source true \
    --num_graphs 50 \
    --task_type construct \
    --budget 10 \
    --output_dir data/fine_tuning/construct_true

# æ··åˆæ•°æ®æº
python scripts/generate_data.py \
    --data_source all \
    --num_graphs 200 \
    --task_type construct \
    --budget 10 \
    --output_dir data/fine_tuning/construct_all
```

### æ­¥éª¤ 3: ç”Ÿæˆæ··åˆä»»åŠ¡æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦åŒæ—¶è®­ç»ƒä¸¤ç§ä»»åŠ¡ï¼Œå¯ä»¥ç”Ÿæˆæ··åˆæ•°æ®é›†ï¼š

```bash
python scripts/generate_data.py \
    --data_source all \
    --num_graphs 200 \
    --task_type both \
    --budget 10 \
    --output_dir data/fine_tuning/mixed_all
```

**æ³¨æ„**: `--task_type both` ä¼šåœ¨åŒä¸€æ‰¹æ¬¡ä¸­éšæœºç”Ÿæˆ dismantle å’Œ construct ä¸¤ç§ä»»åŠ¡çš„æ•°æ®ã€‚

---

## æ•°æ®å‡†å¤‡å’ŒéªŒè¯

### æ­¥éª¤ 4: åˆå¹¶æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦å°†å¤šä¸ªæ•°æ®é›†åˆå¹¶ï¼š

```python
# åˆå¹¶è„šæœ¬ç¤ºä¾‹ (scripts/merge_datasets.py)
import json
from pathlib import Path

def merge_datasets(input_dirs, output_file):
    """åˆå¹¶å¤šä¸ªæ•°æ®é›†"""
    all_samples = []
    
    for input_dir in input_dirs:
        train_file = Path(input_dir) / "train.json"
        if train_file.exists():
            with open(train_file, 'r', encoding='utf-8') as f:
                samples = json.load(f)
                all_samples.extend(samples)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_samples, f, ensure_ascii=False, indent=2)
    
    print(f"åˆå¹¶äº† {len(all_samples)} ä¸ªæ ·æœ¬åˆ° {output_file}")

# ä½¿ç”¨ç¤ºä¾‹
merge_datasets(
    input_dirs=[
        "data/fine_tuning/dismantle_syn",
        "data/fine_tuning/construct_syn"
    ],
    output_file="data/fine_tuning/combined_train.json"
)
```

### æ­¥éª¤ 5: æ•°æ®ç»Ÿè®¡å’ŒéªŒè¯

æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®ï¼š

```python
# æ•°æ®ç»Ÿè®¡è„šæœ¬ç¤ºä¾‹
import json
from pathlib import Path
from collections import Counter

def analyze_dataset(data_file):
    """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    with open(data_file, 'r', encoding='utf-8') as f:
        samples = json.load(f)
    
    print(f"æ€»æ ·æœ¬æ•°: {len(samples)}")
    
    # ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
    task_types = [s['meta'].get('task', 'unknown') for s in samples]
    print(f"ä»»åŠ¡ç±»å‹åˆ†å¸ƒ: {Counter(task_types)}")
    
    # æ•°æ®æºåˆ†å¸ƒ
    data_sources = [s['meta'].get('data_source', 'unknown') for s in samples]
    print(f"æ•°æ®æºåˆ†å¸ƒ: {Counter(data_sources)}")
    
    # èŠ‚ç‚¹æ•°åˆ†å¸ƒ
    node_counts = [s['meta'].get('num_nodes', 0) for s in samples]
    print(f"èŠ‚ç‚¹æ•°èŒƒå›´: [{min(node_counts)}, {max(node_counts)}]")
    print(f"å¹³å‡èŠ‚ç‚¹æ•°: {sum(node_counts) / len(node_counts):.2f}")
    
    # auxiliary_labels ç»Ÿè®¡
    label_values = []
    for s in samples:
        if 'auxiliary_labels' in s:
            label_values.extend(s['auxiliary_labels'].values())
    
    if label_values:
        print(f"æ ‡ç­¾å€¼èŒƒå›´: [{min(label_values):.4f}, {max(label_values):.4f}]")
        print(f"å¹³å‡æ ‡ç­¾å€¼: {sum(label_values) / len(label_values):.4f}")

# ä½¿ç”¨ç¤ºä¾‹
analyze_dataset("data/fine_tuning/dismantle_syn/train.json")
```

---

## æ¨¡å‹è®­ç»ƒé˜¶æ®µ

### æ­¥éª¤ 6: å‡†å¤‡è®­ç»ƒé…ç½®

ç¼–è¾‘ `configs/default.yaml` æˆ–åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶ï¼š

```yaml
# configs/train_config.yaml
data:
  fine_tuning_dir: "data/fine_tuning/dismantle_syn"  # æˆ– construct_syn, mixed_all ç­‰

model:
  llm:
    model_name: "meta-llama/Meta-Llama-3-8B"  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
  
  lora:
    enabled: true
    r: 8
    alpha: 32

training:
  num_epochs: 3
  batch_size: 4
  learning_rate: 2.0e-5
  ranking_loss_type: "listmle"
  phase: 1  # Phase 1: LLM only, Phase 2: Joint training
```

### æ­¥éª¤ 7: Phase 1 è®­ç»ƒï¼ˆLLM LoRA å¾®è°ƒï¼‰

**ç›®æ ‡**: ä»…è®­ç»ƒ LLM çš„ LoRA å‚æ•°ï¼Œå­¦ä¹ è¯­ä¹‰ç†è§£å’Œæ’åºã€‚

```bash
python scripts/train.py \
    --config configs/train_config.yaml \
    --train_data data/fine_tuning/dismantle_syn/train.json \
    --eval_data data/fine_tuning/dismantle_syn/eval.json \
    --phase 1 \
    --epochs 3 \
    --output_dir outputs/dismantle_phase1
```

**è®­ç»ƒæ£€æŸ¥ç‚¹**:
- æ£€æŸ¥ `outputs/dismantle_phase1/training.log` æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
- æ£€æŸ¥ `outputs/dismantle_phase1/checkpoints/` ç›®å½•ä¿å­˜çš„æ¨¡å‹

### æ­¥éª¤ 8: Phase 2 è®­ç»ƒï¼ˆè”åˆè®­ç»ƒï¼Œå¯é€‰ï¼‰

**ç›®æ ‡**: å¦‚æœéœ€è¦ä½¿ç”¨ GNN ç¼–ç å™¨ï¼Œè¿›è¡Œè”åˆè®­ç»ƒã€‚

```bash
# ä¿®æ”¹é…ç½®å¯ç”¨å‡ ä½•ç¼–ç å™¨
# configs/train_config.yaml:
#   model.geometric_encoder.enabled: true
#   training.phase: 2

python scripts/train.py \
    --config configs/train_config.yaml \
    --train_data data/fine_tuning/dismantle_syn/train.json \
    --eval_data data/fine_tuning/dismantle_syn/eval.json \
    --phase 2 \
    --epochs 2 \
    --output_dir outputs/dismantle_phase2 \
    --resume outputs/dismantle_phase1/checkpoints/best
```

---

## æ¨¡å‹è¯„ä¼°é˜¶æ®µ

### æ­¥éª¤ 9: è¯„ä¼°æ¨¡å‹æ€§èƒ½

```python
# è¯„ä¼°è„šæœ¬ç¤ºä¾‹
from src.model.fusion_llm import ResilienceLLM, ModelConfig
from src.data.dataset import create_dataloader
from src.model.loss import RankingMetrics
import torch

# åŠ è½½æ¨¡å‹
config = ModelConfig(...)
model = ResilienceLLM(config)
model.load_pretrained("outputs/dismantle_phase1/checkpoints/best")

# åŠ è½½è¯„ä¼°æ•°æ®
eval_loader = create_dataloader(
    data_path="data/fine_tuning/dismantle_syn/eval.json",
    batch_size=8,
    shuffle=False
)

# è¯„ä¼°æŒ‡æ ‡
model.eval()
all_ndcg = []
all_mrr = []

with torch.no_grad():
    for batch in eval_loader:
        scores = model.get_ranking_scores(
            batch["input_ids"],
            batch["attention_mask"],
            batch["candidate_indices"]
        )
        
        labels = batch["auxiliary_labels"]
        for i in range(scores.shape[0]):
            ndcg = RankingMetrics.ndcg(scores[i], labels[i])
            mrr = RankingMetrics.mrr(scores[i], labels[i])
            all_ndcg.append(ndcg)
            all_mrr.append(mrr)

print(f"Average NDCG: {sum(all_ndcg) / len(all_ndcg):.4f}")
print(f"Average MRR: {sum(all_mrr) / len(all_mrr):.4f}")
```

### æ­¥éª¤ 10: åœ¨çœŸå®ç½‘ç»œä¸Šæµ‹è¯•

```python
# æµ‹è¯•è„šæœ¬ç¤ºä¾‹
from src.env.simulator import NetworkEnvironment
from src.env.metrics import ResilienceMetrics

# åŠ è½½æµ‹è¯•å›¾
test_graph = NetworkEnvironment.load_graph("path/to/test/graph.gml", format="gml")

# åˆ›å»ºç¯å¢ƒ
env = NetworkEnvironment(
    graph=test_graph,
    task_type=TaskType.DISMANTLE,
    budget=10
)

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
# ... å®ç°æ¨ç†å¾ªç¯
```

---

## æ¨èçš„å·¥ä½œæµç¨‹

### æ–¹æ¡ˆ A: åˆ†åˆ«è®­ç»ƒ Dismantle å’Œ Construct

```bash
# 1. ç”Ÿæˆæ•°æ®
python scripts/generate_data.py --data_source syn --task_type dismantle --num_graphs 100 --output_dir data/fine_tuning/dismantle
python scripts/generate_data.py --data_source syn --task_type construct --num_graphs 100 --output_dir data/fine_tuning/construct

# 2. è®­ç»ƒ Dismantle æ¨¡å‹
python scripts/train.py --train_data data/fine_tuning/dismantle/train.json --output_dir outputs/dismantle_model

# 3. è®­ç»ƒ Construct æ¨¡å‹
python scripts/train.py --train_data data/fine_tuning/construct/train.json --output_dir outputs/construct_model
```

### æ–¹æ¡ˆ B: æ··åˆè®­ç»ƒï¼ˆå•æ¨¡å‹å¤„ç†ä¸¤ç§ä»»åŠ¡ï¼‰

```bash
# 1. ç”Ÿæˆæ··åˆæ•°æ®
python scripts/generate_data.py --data_source all --task_type both --num_graphs 200 --output_dir data/fine_tuning/mixed

# 2. è®­ç»ƒæ··åˆæ¨¡å‹
python scripts/train.py --train_data data/fine_tuning/mixed/train.json --output_dir outputs/mixed_model
```

---

## å¸¸è§é—®é¢˜

### Q1: Dismantle å’Œ Construct ä»»åŠ¡çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ

- **Dismantleï¼ˆæ‹†è§£ï¼‰**: ç›®æ ‡æ˜¯**æœ€å°åŒ–**ç½‘ç»œéŸ§æ€§ï¼Œé€‰æ‹©**ç§»é™¤**ç ´åæ€§æœ€å¤§çš„èŠ‚ç‚¹
- **Constructï¼ˆæ„é€ ï¼‰**: ç›®æ ‡æ˜¯**æœ€å¤§åŒ–**ç½‘ç»œéŸ§æ€§ï¼Œé€‰æ‹©**æ·»åŠ **å¢ç›Šæœ€å¤§çš„è¾¹

### Q2: åº”è¯¥ç”Ÿæˆå¤šå°‘æ•°æ®ï¼Ÿ

- **å°å‹å®éªŒ**: 100-200 ä¸ªå›¾ï¼Œæ¯ä¸ªå›¾ 10 æ­¥ â†’ 1000-2000 ä¸ªæ ·æœ¬
- **å®Œæ•´è®­ç»ƒ**: 500-1000 ä¸ªå›¾ï¼Œæ¯ä¸ªå›¾ 10-20 æ­¥ â†’ 5000-20000 ä¸ªæ ·æœ¬
- **å¤§è§„æ¨¡è®­ç»ƒ**: 1000+ ä¸ªå›¾ â†’ 20000+ ä¸ªæ ·æœ¬

### Q3: å¦‚ä½•å¹³è¡¡ Dismantle å’Œ Construct æ•°æ®ï¼Ÿ

å¦‚æœéœ€è¦æ··åˆè®­ç»ƒï¼Œå»ºè®®ï¼š
- 50% Dismantle + 50% Construct
- æˆ–æ ¹æ®å®é™…åº”ç”¨åœºæ™¯è°ƒæ•´æ¯”ä¾‹

### Q4: è®­ç»ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

- **Phase 1 (LoRA)**: 
  - 1000 æ ·æœ¬: ~1-2 å°æ—¶ï¼ˆå• GPUï¼‰
  - 10000 æ ·æœ¬: ~10-20 å°æ—¶
- **Phase 2 (Joint)**: 
  - é€šå¸¸æ¯” Phase 1 æ…¢ 2-3 å€

### Q5: å¦‚ä½•é€‰æ‹© budget å‚æ•°ï¼Ÿ

- **å°å›¾ (<100 èŠ‚ç‚¹)**: budget = 5-10
- **ä¸­å›¾ (100-500 èŠ‚ç‚¹)**: budget = 10-20
- **å¤§å›¾ (>500 èŠ‚ç‚¹)**: budget = 20-50

æ³¨æ„: budget ä¸åº”è¶…è¿‡èŠ‚ç‚¹æ•°çš„ä¸€åŠã€‚

### Q6: æ•°æ®ç”Ÿæˆå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

æ£€æŸ¥ï¼š
1. å›¾æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆ.gml æˆ– .graphmlï¼‰
2. å›¾æ˜¯å¦è¿é€šï¼ˆè„šæœ¬ä¼šè‡ªåŠ¨æå–æœ€å¤§è¿é€šåˆ†é‡ï¼‰
3. å›¾å¤§å°æ˜¯å¦æ»¡è¶³ `--min_graph_size` è¦æ±‚
4. æŸ¥çœ‹é”™è¯¯æ—¥å¿—å®šä½é—®é¢˜

---

## ä¸‹ä¸€æ­¥å»ºè®®

1. **æ•°æ®è´¨é‡æ£€æŸ¥**: ç”Ÿæˆæ•°æ®åï¼Œä½¿ç”¨ç»Ÿè®¡è„šæœ¬éªŒè¯æ•°æ®è´¨é‡
2. **å°è§„æ¨¡å®éªŒ**: å…ˆç”¨å°‘é‡æ•°æ®ï¼ˆ50-100 ä¸ªå›¾ï¼‰æµ‹è¯•å®Œæ•´æµç¨‹
3. **è¶…å‚æ•°è°ƒä¼˜**: æ ¹æ®éªŒè¯é›†æ€§èƒ½è°ƒæ•´å­¦ä¹ ç‡ã€batch size ç­‰
4. **æ¨¡å‹å¯¹æ¯”**: æ¯”è¾ƒä¸åŒé…ç½®ï¼ˆLoRA rankã€loss type ç­‰ï¼‰çš„æ•ˆæœ
5. **çœŸå®åœºæ™¯æµ‹è¯•**: åœ¨çœŸå®ç½‘ç»œæ•°æ®ä¸Šè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›

# è¯„ä¼°å®Œæˆåçš„å®éªŒå»ºè®®

åŸºäºæ‚¨çš„è¯„ä¼°ç»“æœï¼ˆNDCG@5: 0.9013, MRR: 0.9132, Top-1: 0.8632ï¼‰ï¼Œä»¥ä¸‹æ˜¯ç»§ç»­å®éªŒçš„å»ºè®®ã€‚

## ğŸ“Š å½“å‰è¯„ä¼°ç»“æœåˆ†æ

æ‚¨çš„æ¨¡å‹è¡¨ç°**ä¼˜ç§€**ï¼š
- âœ… NDCG@5 > 0.9: æ’åºè´¨é‡éå¸¸é«˜
- âœ… MRR > 0.9: èƒ½å‡†ç¡®è¯†åˆ«æœ€ä¼˜æ“ä½œ
- âœ… Top-1 å‡†ç¡®ç‡ > 0.86: å¤§éƒ¨åˆ†æƒ…å†µä¸‹èƒ½é€‰æ‹©æœ€ä½³æ“ä½œ

## ğŸ¯ ä¸‹ä¸€æ­¥å®éªŒå»ºè®®

### 1. åœ¨å®é™…ç½‘ç»œä¸Šè¿›è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¨èä¼˜å…ˆï¼‰

**ç›®æ ‡**: éªŒè¯æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„è¡¨ç°

```powershell
# æµ‹è¯•æ‹†è§£ä»»åŠ¡
python scripts/inference.py `
    --checkpoint outputs/resilience_llm/checkpoints/best `
    --graph data/raw_graphs/syn/graph_001.gml `
    --task dismantle `
    --budget 10

# æµ‹è¯•æ„é€ ä»»åŠ¡ï¼ˆå¦‚æœæ”¯æŒï¼‰
python scripts/inference.py `
    --checkpoint outputs/resilience_llm/checkpoints/best `
    --graph data/raw_graphs/syn/graph_001.gml `
    --task construct `
    --budget 10
```

**è§‚å¯ŸæŒ‡æ ‡**:
- R_res çš„å˜åŒ–é‡ï¼ˆæ‹†è§£ä»»åŠ¡åº”è¯¥é™ä½ï¼Œæ„é€ ä»»åŠ¡åº”è¯¥æé«˜ï¼‰
- LCC æ¯”ä¾‹çš„å˜åŒ–
- æ“ä½œåºåˆ—çš„åˆç†æ€§

### 2. æ‰¹é‡æµ‹è¯•å¤šä¸ªå›¾

åˆ›å»ºæ‰¹é‡æµ‹è¯•è„šæœ¬ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒå›¾ä¸Šçš„è¡¨ç°ï¼š

```powershell
# åˆ›å»ºæ‰¹é‡æµ‹è¯•è„šæœ¬
python -c "
import glob
from pathlib import Path
import subprocess

checkpoint = 'outputs/resilience_llm/checkpoints/best'
test_graphs = glob.glob('data/raw_graphs/syn/*.gml')[:20]  # æµ‹è¯•å‰20ä¸ªå›¾

results = []
for graph_path in test_graphs:
    print(f'\næµ‹è¯•å›¾: {graph_path}')
    # è¿è¡Œæ¨ç†å¹¶æ”¶é›†ç»“æœ
    # ...
"
```

### 3. åˆ†æé”™è¯¯æ¡ˆä¾‹

**ç›®æ ‡**: æ‰¾å‡ºæ¨¡å‹å¤±è´¥çš„æƒ…å†µï¼Œæ”¹è¿›è®­ç»ƒæ•°æ®æˆ–æ¨¡å‹

```python
# åˆ›å»ºé”™è¯¯åˆ†æè„šæœ¬ scripts/analyze_errors.py
import json
import torch
from scripts.evaluate import evaluate_model

# è¯„ä¼°å¹¶ä¿å­˜è¯¦ç»†ç»“æœ
results = evaluate_model(...)

# æ‰¾å‡º Top-1 é¢„æµ‹é”™è¯¯çš„æ ·æœ¬
error_samples = []
for i, sample in enumerate(eval_loader):
    if predictions[i] != ground_truth[i]:
        error_samples.append({
            'sample_id': sample['sample_id'],
            'predicted': predictions[i],
            'ground_truth': ground_truth[i],
            'scores': scores[i].tolist()
        })

# ä¿å­˜é”™è¯¯æ¡ˆä¾‹
with open('error_analysis.json', 'w') as f:
    json.dump(error_samples, f, indent=2)
```

### 4. ç»§ç»­è®­ç»ƒä»¥æå‡æ€§èƒ½ï¼ˆå¯é€‰ï¼‰

å¦‚æœå¸Œæœ›è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œå¯ä»¥ï¼š

**é€‰é¡¹ A: å¢åŠ è®­ç»ƒè½®æ•°**
```powershell
python scripts/train.py `
    --train_data data/fine_tuning/combined/train.json `
    --eval_data data/fine_tuning/combined/eval.json `
    --output_dir outputs/resilience_llm_v2 `
    --phase 1 `
    --epochs 5 `
    --resume outputs/resilience_llm/checkpoints/best
```

**é€‰é¡¹ B: è°ƒæ•´è¶…å‚æ•°**
```powershell
# å°è¯•ä¸åŒçš„å­¦ä¹ ç‡
python scripts/train.py `
    --train_data data/fine_tuning/combined/train.json `
    --eval_data data/fine_tuning/combined/eval.json `
    --output_dir outputs/resilience_llm_lr_tune `
    --phase 1 `
    --epochs 3 `
    --lr 1e-5  # æˆ– 3e-5, 5e-5
```

**é€‰é¡¹ C: å¢åŠ è®­ç»ƒæ•°æ®**
```powershell
# ç”Ÿæˆæ›´å¤šè®­ç»ƒæ•°æ®
python scripts/generate_data.py `
    --data_source all `
    --num_graphs 500 `
    --output_dir data/fine_tuning/expanded

# åˆå¹¶æ•°æ®é›†
python scripts/merge_datasets.py `
    --input data/fine_tuning/combined/train.json `
    --input data/fine_tuning/expanded/train.json `
    --output data/fine_tuning/merged/train.json
```

### 5. æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

**ç›®æ ‡**: ç†è§£å„ä¸ªç»„ä»¶çš„ä½œç”¨

**å®éªŒ 1: LoRA rank çš„å½±å“**
```powershell
# æµ‹è¯•ä¸åŒçš„ LoRA rank
for r in 4 8 16 32; do
    python scripts/train.py `
        --train_data data/fine_tuning/combined/train.json `
        --eval_data data/fine_tuning/combined/eval.json `
        --output_dir outputs/ablation_lora_r_$r `
        --lora_r $r `
        --epochs 3
done
```

**å®éªŒ 2: æŸå¤±å‡½æ•°çš„å½±å“**
```powershell
# æµ‹è¯•ä¸åŒçš„æŸå¤±å‡½æ•°
python scripts/train.py --ranking_loss_type listmle ...
python scripts/train.py --ranking_loss_type listnet ...
python scripts/train.py --ranking_loss_type combined ...
```

**å®éªŒ 3: è°±æ¢¯åº¦å‰ªæçš„å½±å“**
```powershell
# æµ‹è¯•ä¸åŒçš„ top_k å€¼
for k in 20 50 100 200; do
    # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ spectral_top_k
    python scripts/generate_data.py --spectral_top_k $k ...
done
```

### 6. è·¨æ•°æ®é›†æ³›åŒ–æµ‹è¯•

**ç›®æ ‡**: éªŒè¯æ¨¡å‹åœ¨ä¸åŒç±»å‹å›¾ä¸Šçš„æ³›åŒ–èƒ½åŠ›

```powershell
# åœ¨çœŸå®ç½‘ç»œä¸Šæµ‹è¯•ï¼ˆå¦‚æœè®­ç»ƒæ•°æ®æ˜¯åˆæˆå›¾ï¼‰
python scripts/inference.py `
    --checkpoint outputs/resilience_llm/checkpoints/best `
    --graph data/raw_graphs/true/real_network_001.gml `
    --task dismantle

# åœ¨ä¸åŒè§„æ¨¡çš„å›¾ä¸Šæµ‹è¯•
for size in small medium large; do
    python scripts/inference.py `
        --checkpoint outputs/resilience_llm/checkpoints/best `
        --graph data/raw_graphs/${size}/graph_001.gml `
        --task dismantle
done
```

### 7. å¯¹æ¯”å®éªŒ

**ç›®æ ‡**: ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

```python
# åˆ›å»ºå¯¹æ¯”è„šæœ¬ scripts/compare_baselines.py
from src.env.simulator import NetworkEnvironment
from src.env.metrics import ResilienceMetrics

# åŸºçº¿æ–¹æ³• 1: éšæœºé€‰æ‹©
def random_baseline(env, budget):
    # ...

# åŸºçº¿æ–¹æ³• 2: åº¦æ•°ä¸­å¿ƒæ€§
def degree_baseline(env, budget):
    # ...

# åŸºçº¿æ–¹æ³• 3: æ‚¨çš„æ¨¡å‹
def model_baseline(env, budget, model):
    # ...

# å¯¹æ¯”ç»“æœ
results = {
    'random': [],
    'degree': [],
    'model': []
}
```

### 8. å¯è§†åŒ–åˆ†æ

**ç›®æ ‡**: å¯è§†åŒ–æ¨¡å‹å†³ç­–è¿‡ç¨‹

```python
# åˆ›å»ºå¯è§†åŒ–è„šæœ¬ scripts/visualize_decisions.py
import matplotlib.pyplot as plt
import networkx as nx

def visualize_attack_sequence(graph, attack_sequence, save_path):
    """å¯è§†åŒ–æ”»å‡»åºåˆ—å¯¹ç½‘ç»œçš„å½±å“"""
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    
    for step, node in enumerate(attack_sequence[:10]):
        # ç»˜åˆ¶å½“å‰å›¾çŠ¶æ€
        # ...
    
    plt.savefig(save_path)
```

## ğŸ“ˆ å®éªŒè®°å½•å»ºè®®

å»ºè®®åˆ›å»ºä¸€ä¸ªå®éªŒæ—¥å¿—ï¼Œè®°å½•æ¯æ¬¡å®éªŒçš„ç»“æœï¼š

```markdown
# å®éªŒæ—¥å¿—

## å®éªŒ 1: åŸºç¡€è®­ç»ƒ
- æ—¥æœŸ: 2026-01-14
- é…ç½®: Phase 1, LoRA r=8, epochs=3
- ç»“æœ: NDCG@5=0.9013, MRR=0.9132, Top-1=0.8632
- å¤‡æ³¨: è¡¨ç°ä¼˜ç§€

## å®éªŒ 2: æ¨ç†æµ‹è¯•
- æ—¥æœŸ: 2026-01-14
- æµ‹è¯•å›¾: 20 ä¸ªåˆæˆå›¾
- ç»“æœ: å¹³å‡ R_res é™ä½ 0.XX
- å¤‡æ³¨: éœ€è¦è¿›ä¸€æ­¥åˆ†æ
```

## ğŸ¯ ä¼˜å…ˆçº§å»ºè®®

åŸºäºæ‚¨å½“å‰çš„ä¼˜ç§€è¯„ä¼°ç»“æœï¼Œå»ºè®®æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§è¿›è¡Œï¼š

1. **é«˜ä¼˜å…ˆçº§**:
   - âœ… åœ¨å®é™…ç½‘ç»œä¸Šè¿›è¡Œæ¨ç†æµ‹è¯•ï¼ˆéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼‰
   - âœ… æ‰¹é‡æµ‹è¯•å¤šä¸ªå›¾ï¼ˆè¯„ä¼°ç¨³å®šæ€§ï¼‰

2. **ä¸­ä¼˜å…ˆçº§**:
   - åˆ†æé”™è¯¯æ¡ˆä¾‹ï¼ˆæ‰¾å‡ºæ”¹è¿›æ–¹å‘ï¼‰
   - è·¨æ•°æ®é›†æ³›åŒ–æµ‹è¯•ï¼ˆéªŒè¯é²æ£’æ€§ï¼‰

3. **ä½ä¼˜å…ˆçº§**:
   - æ¶ˆèå®éªŒï¼ˆç†è§£æ¨¡å‹ç»„ä»¶ï¼‰
   - ç»§ç»­è®­ç»ƒï¼ˆå¦‚æœæ€§èƒ½å·²æ»¡è¶³éœ€æ±‚ï¼Œå¯èƒ½ä¸éœ€è¦ï¼‰

## ğŸ“ å¿«é€Ÿå¼€å§‹å‘½ä»¤

```powershell
# 1. æ¨ç†æµ‹è¯•ï¼ˆå•å›¾ï¼‰
python scripts/inference.py `
    --checkpoint outputs/resilience_llm/checkpoints/best `
    --graph data/raw_graphs/syn/graph_001.gml `
    --task dismantle

# 2. é‡æ–°è¯„ä¼°ï¼ˆç¡®è®¤ç»“æœï¼‰
python scripts/evaluate.py `
    --checkpoint outputs/resilience_llm/checkpoints/best `
    --eval_data data/fine_tuning/combined/eval.json

# 3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
Get-Content outputs/resilience_llm/training.log -Tail 50
```

## ğŸ” é—®é¢˜è¯Šæ–­

å¦‚æœæ¨ç†ç»“æœä¸ç†æƒ³ï¼Œæ£€æŸ¥ï¼š

1. **æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½**
   ```python
   # æ£€æŸ¥æ¨¡å‹å‚æ•°
   print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
   ```

2. **æ•°æ®æ ¼å¼æ˜¯å¦åŒ¹é…**
   ```python
   # æ£€æŸ¥æ•°æ®æ ¼å¼
   sample = eval_loader.dataset[0]
   print(sample.keys())
   ```

3. **OCG æå–æ˜¯å¦æ­£å¸¸**
   ```python
   # æ£€æŸ¥ OCG æå–
   ocg_data = extractor.extract_ocg(...)
   print(f"OCG èŠ‚ç‚¹æ•°: {len(ocg_data['nodes'])}")
   ```

---

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸš€

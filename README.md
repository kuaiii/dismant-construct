# ğŸ”— Neural-Symbolic Network Resilience Optimization Framework

ç¥ç»ç¬¦å·ç½‘ç»œéŸ§æ€§ä¼˜åŒ–æ¡†æ¶ - ç»“åˆå¤§è¯­è¨€æ¨¡å‹ (LLM) å’Œå›¾ç¥ç»ç½‘ç»œ (GNN) çš„ç½‘ç»œéŸ§æ€§ä¼˜åŒ–ç³»ç»Ÿã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬æ¡†æ¶å®ç°äº†ä¸€ä¸ªç¥ç»ç¬¦å·ç³»ç»Ÿï¼Œç”¨äºç½‘ç»œéŸ§æ€§ä¼˜åŒ–ä»»åŠ¡ï¼ˆæ‹†è§£/æ„é€ ï¼‰ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **æ“ä½œä¸­å¿ƒå›¾ (OCG)**: æå–å€™é€‰èŠ‚ç‚¹å‘¨å›´çš„å±€éƒ¨å­å›¾ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯
2. **è°±æ¢¯åº¦å‰ªæ**: å°†å€™é€‰ç©ºé—´ä» O(NÂ²) é™ä½åˆ° O(N)
3. **ListMLE æ’åºå­¦ä¹ **: ä½¿ç”¨ `auxiliary_labels` è¿›è¡Œæ’åºæŸå¤±ä¼˜åŒ–
4. **LoRA å¾®è°ƒ**: å‚æ•°é«˜æ•ˆåœ°å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
project_root/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_graphs/           # BA, ER åŸå§‹å›¾æ•°æ®
â”‚   â””â”€â”€ fine_tuning/          # ç”Ÿæˆçš„ JSON å¾®è°ƒæ•°æ®
â”‚       â””â”€â”€ sample_data.json  # ç¤ºä¾‹æ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ simulator.py      # NetworkEnvironment (å›¾çŠ¶æ€ç®¡ç†ã€è°±æ¢¯åº¦å‰ªæ)
â”‚   â”‚   â””â”€â”€ metrics.py        # R_res éŸ§æ€§ç§¯åˆ†è®¡ç®—
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ ocg_builder.py    # OCG æå–å’Œ Prompt ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ dataset.py        # PyTorch Dataset å’Œ DataLoader
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ fusion_llm.py     # ResilienceLLM ä¸»æ¨¡å‹æ¶æ„
â”‚   â”‚   â””â”€â”€ loss.py           # ListMLELoss æ’åºæŸå¤±å‡½æ•°
â”‚   â””â”€â”€ trainer/
â”‚       â””â”€â”€ train.py          # è®­ç»ƒå¾ªç¯å’Œè¯„ä¼°
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_data.py      # æ•°æ®ç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ train.py              # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml          # é»˜è®¤é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt          # ä¾èµ–é¡¹
â””â”€â”€ README.md
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# æœ€å°å®‰è£…ï¼ˆæµ‹è¯•ç”¨ï¼‰
pip install transformers peft

# å®Œæ•´å®‰è£…ï¼ˆæ¨èï¼‰
pip install -r requirements.txt
```

**æ³¨æ„**ï¼šè¯¦ç»†å®‰è£…è¯´æ˜è¯·å‚è€ƒ [å®‰è£…æŒ‡å—](INSTALL.md)

### 2. ç”Ÿæˆè®­ç»ƒæ•°æ®

**ä»åˆæˆ/çœŸå®ç½‘ç»œæ•°æ®ç”Ÿæˆï¼š**

```bash
# ä»åˆæˆç½‘ç»œæ•°æ®ç”Ÿæˆï¼ˆsyn ç›®å½•ï¼‰
python scripts/generate_data.py \
    --data_source syn \
    --num_graphs 100 \
    --output_dir data/fine_tuning

# ä»çœŸå®ç½‘ç»œæ•°æ®ç”Ÿæˆï¼ˆtrue ç›®å½•ï¼‰
python scripts/generate_data.py \
    --data_source true \
    --num_graphs 50 \
    --output_dir data/fine_tuning

# æ··åˆä½¿ç”¨ï¼ˆsyn + trueï¼‰
python scripts/generate_data.py \
    --data_source all \
    --num_graphs 200 \
    --output_dir data/fine_tuning
```

**ç”Ÿæˆ BA/ER å›¾ï¼ˆåŸæœ‰æ–¹å¼ï¼‰ï¼š**

```bash
python scripts/generate_data.py \
    --data_source generate \
    --graph_type ba \
    --num_graphs 100 \
    --min_nodes 50 \
    --max_nodes 200 \
    --output_dir data/fine_tuning
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [æ•°æ®ç”ŸæˆæŒ‡å—](docs/data_generation_guide.md)

### 3. ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰

```bash
# æ–¹æ³• 1: ä½¿ç”¨ä¸‹è½½è„šæœ¬ï¼ˆæ¨èï¼‰
python scripts/download_model.py

# æ–¹æ³• 2: ä½¿ç”¨æµ‹è¯•è„šæœ¬ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
python scripts/test_model_loading.py
```

**æ³¨æ„**: æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° HuggingFace ç¼“å­˜ç›®å½•ï¼ˆçº¦ 3GBï¼‰

### 4. å¯åŠ¨è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python scripts/train.py \
    --train_data data/fine_tuning/combined/train.json \
    --eval_data data/fine_tuning/combined/eval.json \
    --output_dir outputs/mixed_model \
    --phase 1 \
    --epochs 3

# å°è§„æ¨¡æµ‹è¯•ï¼ˆæ¨èå…ˆè¿è¡Œï¼‰
python scripts/train.py \
    --train_data data/fine_tuning/combined/train.json \
    --eval_data data/fine_tuning/combined/eval.json \
    --output_dir outputs/test_run \
    --phase 1 \
    --epochs 1 \
    --batch_size 1
```

**è¯¦ç»†è¯´æ˜**: è¯·å‚è€ƒ [å¼€å§‹è®­ç»ƒæŒ‡å—](docs/training_start_guide.md)

### 5. æ¨¡å‹æ¨ç†

```bash
# Dismantle ä»»åŠ¡æ¨ç†ï¼ˆç§»é™¤èŠ‚ç‚¹ä»¥é™ä½éŸ§æ€§ï¼‰
python scripts/inference.py \
    --checkpoint outputs/dismantle_model/checkpoints/best \
    --graph data/raw_graphs/true/Colt.gml \
    --task dismantle \
    --budget 10

# Construct ä»»åŠ¡æ¨ç†ï¼ˆæ·»åŠ è¾¹ä»¥æé«˜éŸ§æ€§ï¼‰
python scripts/inference.py \
    --checkpoint outputs/construct_model/checkpoints/best \
    --graph data/raw_graphs/true/Colt.gml \
    --task construct \
    --budget 10
```

> ğŸ“– **è¯¦ç»†æŒ‡å—**: 
> - Dismantle ä»»åŠ¡: å‚è€ƒ `docs/workflow_guide.md`
> - Construct ä»»åŠ¡: å‚è€ƒ `docs/construct_experiment_guide.md`

## ğŸ“Š æ ¸å¿ƒæ¨¡å—è¯´æ˜

### NetworkEnvironment (simulator.py)

ç½‘ç»œç¯å¢ƒæ¨¡æ‹Ÿå™¨ï¼Œè´Ÿè´£ï¼š
- ç»´æŠ¤å›¾çŠ¶æ€ G_t
- æ‰§è¡Œ **è°±æ¢¯åº¦å‰ªæ** (Spectral Gradient Pruning)
- è®¡ç®—å€™é€‰æ“ä½œçš„å½±å“åˆ†æ•°

```python
from src.env.simulator import NetworkEnvironment, create_environment

# åˆ›å»ºç¯å¢ƒ
env = create_environment(
    graph_type="ba",
    num_nodes=100,
    task="dismantle",
    budget=10,
    spectral_top_k=50
)

# è·å–å€™é€‰èŠ‚ç‚¹ (è°±æ¢¯åº¦å‰ªæå)
candidates = env.prune_candidates()

# æ‰§è¡Œæ“ä½œ
reward, done = env.execute_operation(operation)
```

**è°±æ¢¯åº¦è®¡ç®—åŸç†**:
- è®¡ç®—å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ L = D - A
- æ±‚è§£ Fiedler å‘é‡ (ç¬¬äºŒå°ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡)
- èŠ‚ç‚¹ i çš„è°±æ¢¯åº¦ â‰ˆ |vâ‚‚[i]|Â² Ã— d_i

### OCGExtractor (ocg_builder.py)

æ“ä½œä¸­å¿ƒå›¾æå–å™¨ï¼Œè´Ÿè´£ï¼š
- æå–å€™é€‰èŠ‚ç‚¹çš„ k-hop å­å›¾
- è®¡ç®—ç»“æ„ç‰¹å¾ï¼ˆåº¦æ•°ã€èšç±»ç³»æ•°ã€å‰²ç‚¹ç­‰ï¼‰
- èåˆè¯­ä¹‰ä¿¡æ¯ç”Ÿæˆ Prompt

```python
from src.data.ocg_builder import OCGExtractor

extractor = OCGExtractor(hop_distance=1, language="zh")

# æå– OCG
ocg_data = extractor.extract_ocg(
    graph=env.graph,
    candidate_nodes=candidates,
    task_type="dismantle",
    current_step=1,
    total_steps=10,
    node_semantics=semantics
)

# æ„å»ºè®­ç»ƒæ ·æœ¬
sample = extractor.build_conversation_data(
    ocg_data=ocg_data,
    ground_truth_ranking=["op_01", "op_03", "op_02"],
    auxiliary_labels={"op_01": 0.95, "op_02": 0.15, "op_03": 0.40}
)
```

### ListMLELoss (loss.py)

åŸºäº Plackett-Luce æ¨¡å‹çš„æ’åºæŸå¤±å‡½æ•°ï¼š

```python
from src.model.loss import ListMLELoss

loss_fn = ListMLELoss(temperature=1.0)

# scores: æ¨¡å‹é¢„æµ‹åˆ†æ•° [batch_size, num_candidates]
# auxiliary_labels: çœŸå®å½±å“åˆ†æ•° [batch_size, num_candidates]
loss = loss_fn(scores, auxiliary_labels, mask=candidate_mask)
```

**ListMLE æ•°å­¦åŸç†**:
```
L = -log P(Ï€|s) = -Î£áµ¢ log(exp(s_{Ï€_i}) / Î£â±¼â‰¥áµ¢ exp(s_{Ï€_j}))
```

å…¶ä¸­ Ï€ æ˜¯æ ¹æ® `auxiliary_labels` å¾—åˆ°çš„çœŸå®æ’åºã€‚

### ResilienceLLM (fusion_llm.py)

ä¸»æ¨¡å‹æ¶æ„ï¼Œæ”¯æŒï¼š
- LoRA å¾®è°ƒ LLM
- å¯é€‰çš„å‡ ä½•ç¼–ç å™¨ (GNN)
- é—¨æ§èåˆæ¨¡å—

```python
from src.model.fusion_llm import ResilienceLLM, ModelConfig

config = ModelConfig(
    llm_model_name="meta-llama/Meta-Llama-3-8B",
    use_lora=True,
    lora_r=8,
    use_geometric_encoder=False
)

model = ResilienceLLM(config)
model.initialize(device="cuda")

# è·å–æ’åºåˆ†æ•°
scores = model.get_ranking_scores(input_ids, attention_mask, candidate_indices)
```

## ğŸ“ æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®é‡‡ç”¨å¯¹è¯æ ¼å¼ï¼Œå…¼å®¹ LLaMA-Factory ç­‰å¾®è°ƒæ¡†æ¶ï¼š

```json
{
  "id": "train_dismantle_001",
  "meta": {
    "task": "dismantle",
    "budget_step": "1/10"
  },
  "conversations": [
    {"from": "system", "value": "ç³»ç»Ÿæç¤º..."},
    {"from": "user", "value": "OCG æè¿°å’Œå€™é€‰åˆ—è¡¨..."},
    {"from": "assistant", "value": "æ¨ç†å’Œæ’åºç»“æœ..."}
  ],
  "auxiliary_labels": {
    "op_01": 0.95,
    "op_02": 0.15,
    "op_03": 0.40
  }
}
```

**å…³é”®å­—æ®µ**:
- `auxiliary_labels`: ç”¨äº ListMLE è®¡ç®—çš„çœŸå®å½±å“åˆ†æ•°
- `conversations`: æ ‡å‡†å¯¹è¯æ ¼å¼ï¼Œç”¨äº LLM å¾®è°ƒ

## ğŸ”„ æ•°æ®æµ

```
Raw Graph (BA/ER)
      â†“
NetworkEnvironment (è°±æ¢¯åº¦å‰ªæ)
      â†“
OCGExtractor (æå– OCG)
      â†“
JSON Data (conversations + auxiliary_labels)
      â†“
ResilienceDataset (åŠ è½½å’Œé¢„å¤„ç†)
      â†“
ResilienceLLM (æ¨¡å‹å‰å‘ä¼ æ’­)
      â†“
ListMLELoss (æ’åºæŸå¤±è®¡ç®—)
      â†“
Model Update (LoRA å‚æ•°æ›´æ–°)
```

## âš™ï¸ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹ (`configs/default.yaml`):

```yaml
model:
  llm:
    model_name: "meta-llama/Meta-Llama-3-8B"
  lora:
    enabled: true
    r: 8
    alpha: 32

training:
  loss:
    ranking_type: "listmle"  # listmle, listnet, combined
    ranking_weight: 1.0
    lm_weight: 0.5

environment:
  spectral_pruning:
    enabled: true
    top_k: 50
```

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

- **NDCG** (Normalized Discounted Cumulative Gain)
- **MRR** (Mean Reciprocal Rank)
- **Precision@K**
- **Kendall's Tau** (æ’åºç›¸å…³æ€§)

## ğŸ”§ å…³é”®ç‚¹æ£€æŸ¥

1. âœ… **ListMLE**: `loss.py` ä¸­å®ç°äº†åŸºäº `auxiliary_labels` çš„æ’åºæŸå¤±
2. âœ… **è°±æ¢¯åº¦å‰ªæ**: `simulator.py` ä¸­é¢„ç•™äº† `compute_spectral_gradient` å’Œ `prune_candidates` æ¥å£
3. âœ… **OCG æ„å»º**: `ocg_builder.py` ä¸­å®ç°äº†å›¾çŠ¶æ€åˆ° Prompt æ–‡æœ¬çš„è½¬æ¢

## ğŸ“ TODO

- [ ] å®ç°å®Œæ•´çš„è°±æ¢¯åº¦è®¡ç®— (ç¨€ç–ç‰¹å¾å€¼æ±‚è§£)
- [ ] æ·»åŠ æ›´å¤š GNN ç¼–ç å™¨ç±»å‹ (GAT, GraphTransformer)
- [ ] æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ
- [ ] æ·»åŠ æ¨ç†æœåŠ¡ API

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®ç”Ÿæˆè„šæœ¬
ä»ç½‘ç»œæ¨¡æ‹Ÿä¸­ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚

ç”¨æ³•:
    # ä»åˆæˆç½‘ç»œæ•°æ®ç”Ÿæˆ
    python scripts/generate_data.py --data_source syn --num_graphs 100 --output_dir data/fine_tuning
    
    # ä»çœŸå®ç½‘ç»œæ•°æ®ç”Ÿæˆ
    python scripts/generate_data.py --data_source true --num_graphs 50 --output_dir data/fine_tuning
    
    # æ··åˆä½¿ç”¨ï¼ˆåˆæˆ+çœŸå®+ç”Ÿæˆï¼‰
    python scripts/generate_data.py --data_source all --num_graphs 200 --output_dir data/fine_tuning
    
    # ä»…ç”Ÿæˆ BA/ER å›¾ï¼ˆåŸæœ‰æ–¹å¼ï¼‰
    python scripts/generate_data.py --data_source generate --graph_type ba --num_graphs 100
"""

import argparse
import json
import random
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import networkx as nx


def generate_node_semantics(num_nodes: int, graph_type: str = "generic", node_ids: Optional[List] = None) -> Dict:
    """
    ç”ŸæˆèŠ‚ç‚¹è¯­ä¹‰æè¿°
    
    Args:
        num_nodes: èŠ‚ç‚¹æ•°é‡
        graph_type: å›¾ç±»å‹ï¼Œç”¨äºç”Ÿæˆç›¸å…³è¯­ä¹‰
        node_ids: èŠ‚ç‚¹IDåˆ—è¡¨ï¼ˆå¦‚æœæä¾›ï¼Œä½¿ç”¨è¿™äº›IDï¼›å¦åˆ™ä½¿ç”¨ 0 åˆ° num_nodes-1ï¼‰
    
    Returns:
        èŠ‚ç‚¹è¯­ä¹‰å­—å…¸ {node_id: semantic_description}
    """
    # é¢„å®šä¹‰è¯­ä¹‰æ¨¡æ¿
    server_roles = [
        "æ ¸å¿ƒè°ƒåº¦æœåŠ¡å™¨ï¼Œè´Ÿè´£å…¨ç½‘åŒæ­¥",
        "è¾¹ç¼˜è·¯ç”±å™¨ï¼Œè´Ÿè´£æœ¬åœ°æµé‡",
        "å¤‡ç”¨ç”µæºæ¥å£",
        "æ•°æ®å­˜å‚¨èŠ‚ç‚¹",
        "ç½‘å…³èŠ‚ç‚¹ï¼Œè¿æ¥å¤–éƒ¨ç½‘ç»œ",
        "è´Ÿè½½å‡è¡¡å™¨",
        "ç›‘æ§æœåŠ¡å™¨",
        "æ—¥å¿—æ”¶é›†å™¨",
        "è®¤è¯æœåŠ¡å™¨",
        "ç¼“å­˜æœåŠ¡å™¨"
    ]
    
    infra_roles = [
        "ä¸»å˜ç”µç«™",
        "é…ç”µç«™",
        "è¾“ç”µå¡”",
        "ç”¨æˆ·æ¥å…¥ç‚¹",
        "å‚¨èƒ½è®¾å¤‡",
        "å‘ç”µç«™",
        "è°ƒåº¦ä¸­å¿ƒ",
        "å¤‡ç”¨çº¿è·¯èŠ‚ç‚¹"
    ]
    
    social_roles = [
        "æ„è§é¢†è¢–",
        "ç¤¾åŒºç®¡ç†å‘˜",
        "æ™®é€šç”¨æˆ·",
        "æ´»è·ƒè´¡çŒ®è€…",
        "ä¿¡æ¯ä¸­è½¬èŠ‚ç‚¹"
    ]
    
    if graph_type == "network":
        roles = server_roles
    elif graph_type == "infra":
        roles = infra_roles
    elif graph_type == "social":
        roles = social_roles
    else:
        roles = server_roles + infra_roles
    
    semantics = {}
    if node_ids is None:
        node_ids = list(range(num_nodes))
    
    for node_id in node_ids:
        role = random.choice(roles)
        # æ·»åŠ ä¸€äº›éšæœºæ€§
        importance = random.choice(["å…³é”®", "é‡è¦", "æ™®é€š", "è¾…åŠ©"])
        semantics[node_id] = f"{importance}{role}"
    
    return semantics


def load_graph_from_file(filepath: Path) -> Optional[nx.Graph]:
    """
    ä»æ–‡ä»¶åŠ è½½å›¾
    
    Args:
        filepath: å›¾æ–‡ä»¶è·¯å¾„
    
    Returns:
        NetworkX å›¾å¯¹è±¡ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å› None
    """
    try:
        if filepath.suffix == '.gml':
            # GML æ–‡ä»¶å¯èƒ½ä½¿ç”¨ä¸åŒçš„æ ‡ç­¾ï¼Œå°è¯•å‡ ç§æ–¹å¼
            try:
                graph = nx.read_gml(filepath, label='id')
            except Exception:
                try:
                    graph = nx.read_gml(filepath)
                except Exception:
                    # æœ€åå°è¯•ä½¿ç”¨ label=None
                    graph = nx.read_gml(filepath, label=None)
        elif filepath.suffix == '.graphml':
            graph = nx.read_graphml(filepath)
        else:
            print(f"  Warning: Unsupported file format: {filepath.suffix}")
            return None
        
        # è½¬æ¢ä¸ºæ— å‘å›¾ï¼ˆå¦‚æœæ˜¯æœ‰å‘å›¾ï¼‰
        if graph.is_directed():
            graph = graph.to_undirected()
        
        # åªä¿ç•™æœ€å¤§è¿é€šåˆ†é‡
        if graph.number_of_nodes() > 0 and not nx.is_connected(graph):
            largest_cc = max(nx.connected_components(graph), key=len)
            graph = graph.subgraph(largest_cc).copy()
        
        return graph
    except Exception as e:
        print(f"  Error loading {filepath}: {e}")
        return None


def get_graph_files(data_source: str, raw_graphs_dir: Path) -> List[Tuple[Path, str]]:
    """
    è·å–å›¾æ–‡ä»¶åˆ—è¡¨
    
    Args:
        data_source: æ•°æ®æºç±»å‹ ("syn", "true", "all")
        raw_graphs_dir: åŸå§‹å›¾æ•°æ®ç›®å½•
    
    Returns:
        List[(filepath, source_type)]: å›¾æ–‡ä»¶è·¯å¾„å’Œæ¥æºç±»å‹çš„åˆ—è¡¨
    """
    graph_files = []
    
    if data_source in ["syn", "all"]:
        syn_dir = raw_graphs_dir / "syn"
        if syn_dir.exists():
            syn_files = list(syn_dir.glob("*.gml"))
            graph_files.extend([(f, "syn") for f in syn_files])
    
    if data_source in ["true", "all"]:
        true_dir = raw_graphs_dir / "true"
        if true_dir.exists():
            true_gml = list(true_dir.glob("*.gml"))
            true_graphml = list(true_dir.glob("*.graphml"))
            graph_files.extend([(f, "true") for f in true_gml + true_graphml])
    
    return graph_files


def generate_single_graph_data(
    graph: Optional[nx.Graph] = None,
    graph_type: Optional[str] = None,
    num_nodes: Optional[int] = None,
    task_type: str = "dismantle",
    budget: int = 10,
    graph_idx: int = 0,
    graph_file: Optional[Path] = None,
    data_source: str = "generate",
    semantic_type: str = "generic"
) -> List[Dict]:
    """
    ä¸ºå•ä¸ªå›¾ç”Ÿæˆè®­ç»ƒæ•°æ®
    
    Args:
        graph: NetworkX å›¾å¯¹è±¡ï¼ˆå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼‰
        graph_type: å›¾ç±»å‹ ("ba", "er")ï¼Œä»…åœ¨ graph=None æ—¶ä½¿ç”¨
        num_nodes: èŠ‚ç‚¹æ•°ï¼Œä»…åœ¨ graph=None æ—¶ä½¿ç”¨
        task_type: ä»»åŠ¡ç±»å‹ ("dismantle", "construct")
        budget: æ“ä½œé¢„ç®—
        graph_idx: å›¾ç´¢å¼•
        graph_file: å›¾æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè®°å½•ï¼‰
        data_source: æ•°æ®æ¥æº ("generate", "syn", "true", "all")
        semantic_type: è¯­ä¹‰ç±»å‹
    
    Returns:
        æ ·æœ¬åˆ—è¡¨
    """
    from src.env.simulator import NetworkEnvironment, TaskType
    from src.env.metrics import ResilienceMetrics
    from src.data.ocg_builder import OCGExtractor
    
    # å¦‚æœæ²¡æœ‰æä¾›å›¾ï¼Œåˆ™ç”Ÿæˆå›¾
    if graph is None:
        if graph_type == "ba":
            m = max(2, num_nodes // 20) if num_nodes else 3
            graph = nx.barabasi_albert_graph(num_nodes, m)
        elif graph_type == "er":
            p = 3.0 / num_nodes if num_nodes else 0.05
            graph = nx.erdos_renyi_graph(num_nodes, p)
            # ç¡®ä¿è¿é€š
            while not nx.is_connected(graph):
                graph = nx.erdos_renyi_graph(num_nodes, p * 1.2)
        else:
            raise ValueError(f"Unknown graph type: {graph_type}")
    
    # ç¡®ä¿å›¾æ˜¯è¿é€šçš„ï¼ˆåªä¿ç•™æœ€å¤§è¿é€šåˆ†é‡ï¼‰
    if not nx.is_connected(graph):
        largest_cc = max(nx.connected_components(graph), key=len)
        graph = graph.subgraph(largest_cc).copy()
    
    actual_num_nodes = graph.number_of_nodes()
    
    # ç”Ÿæˆè¯­ä¹‰ï¼ˆåŸºäºå®é™…èŠ‚ç‚¹æ•°å’ŒèŠ‚ç‚¹IDï¼‰
    node_ids = list(graph.nodes())
    node_semantics = generate_node_semantics(actual_num_nodes, semantic_type, node_ids=node_ids)
    
    # åˆ›å»ºç¯å¢ƒ
    task = TaskType.DISMANTLE if task_type == "dismantle" else TaskType.CONSTRUCT
    env = NetworkEnvironment(
        graph=graph,
        task_type=task,
        budget=min(budget, actual_num_nodes // 2),  # é¢„ç®—ä¸èƒ½è¶…è¿‡èŠ‚ç‚¹æ•°çš„ä¸€åŠ
        spectral_top_k=min(10, actual_num_nodes // 5),
        node_semantics=node_semantics
    )
    
    # åˆå§‹åŒ–å·¥å…·
    metrics = ResilienceMetrics()
    extractor = OCGExtractor(language="zh")
    
    samples = []
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„ç”Ÿæˆé€»è¾‘
    if task_type == "dismantle":
        samples = _generate_dismantle_data(
            env, metrics, extractor, budget, graph_idx, graph_file,
            data_source, semantic_type, node_semantics, actual_num_nodes
        )
    else:  # construct
        samples = _generate_construct_data(
            env, metrics, extractor, budget, graph_idx, graph_file,
            data_source, semantic_type, node_semantics, actual_num_nodes
        )
    
    return samples


def _generate_dismantle_data(
    env, metrics, extractor, budget, graph_idx, graph_file,
    data_source, semantic_type, node_semantics, actual_num_nodes
) -> List[Dict]:
    """ç”Ÿæˆ dismantle ä»»åŠ¡çš„è®­ç»ƒæ•°æ®"""
    samples = []
    
    # æ¨¡æ‹Ÿæ“ä½œåºåˆ—
    for step in range(budget):
        if env.graph.number_of_nodes() < 3:
            break
        
        # è·å–å€™é€‰èŠ‚ç‚¹ (è¿™é‡Œç”¨ç®€å•çš„åº¦æ•°æ’åºæ¨¡æ‹Ÿè°±æ¢¯åº¦å‰ªæ)
        nodes = list(env.graph.nodes())
        degrees = dict(env.graph.degree())
        sorted_nodes = sorted(nodes, key=lambda x: degrees[x], reverse=True)
        candidates = sorted_nodes[:min(5, len(sorted_nodes))]
        
        if not candidates:
            break
        
        # è®¡ç®—çœŸå®å½±å“åˆ†æ•° (auxiliary_labels)
        impact_scores = metrics.batch_compute_impact_scores(env.graph, candidates)
        
        # æ„å»ºæ“ä½œå’Œæ ‡ç­¾
        auxiliary_labels = {}
        operations = []
        for idx, node in enumerate(candidates):
            op_id = f"op_{idx+1:02d}"
            # å½’ä¸€åŒ–åˆ†æ•°åˆ° [0, 1]
            score = impact_scores.get(node, 0)
            if score < 0:
                score = 0
            auxiliary_labels[op_id] = round(score, 4)
            operations.append({"op_id": op_id, "target": node})
        
        # è·å–æ­£ç¡®æ’åº
        ground_truth = sorted(
            auxiliary_labels.items(),
            key=lambda x: x[1],
            reverse=True
        )
        ground_truth_ranking = [op_id for op_id, _ in ground_truth]
        
        # ç”Ÿæˆæ¨ç†è¿‡ç¨‹
        reasoning = generate_reasoning_trace_dismantle(
            candidates, 
            auxiliary_labels, 
            ground_truth_ranking,
            env.graph,
            node_semantics
        )
        
        # æå– OCG å¹¶æ„å»ºæ ·æœ¬
        ocg_data = extractor.extract_ocg(
            graph=env.graph,
            candidate_nodes=candidates,
            task_type="dismantle",
            current_step=step + 1,
            total_steps=budget,
            node_semantics=node_semantics
        )
        
        sample = extractor.build_conversation_data(
            ocg_data=ocg_data,
            ground_truth_ranking=ground_truth_ranking,
            auxiliary_labels=auxiliary_labels,
            reasoning_trace=reasoning
        )
        
        # æ›´æ–°æ ·æœ¬ ID å’Œå…ƒæ•°æ®
        graph_type_str = data_source if data_source != "generate" else "ba"
        sample["id"] = f"train_dismantle_{data_source}_{graph_idx:04d}_{step:02d}"
        sample["meta"]["graph_type"] = graph_type_str
        sample["meta"]["num_nodes"] = actual_num_nodes
        sample["meta"]["graph_idx"] = graph_idx
        sample["meta"]["data_source"] = data_source
        sample["meta"]["sign"] = -1  # ç¬¦å·å‡½æ•°ï¼šdismantle æ˜¯å‡å°éŸ§æ€§
        if graph_file:
            sample["meta"]["graph_file"] = str(graph_file.name)
        
        samples.append(sample)
        
        # æ‰§è¡Œæœ€ä½³æ“ä½œ
        if ground_truth_ranking:
            best_op = ground_truth_ranking[0]
            best_node = operations[int(best_op.split("_")[1]) - 1]["target"]
            if best_node in env.graph:
                env.graph.remove_node(best_node)
        
        env.current_step += 1
    
    return samples


def _generate_construct_data(
    env, metrics, extractor, budget, graph_idx, graph_file,
    data_source, semantic_type, node_semantics, actual_num_nodes
) -> List[Dict]:
    """ç”Ÿæˆ construct ä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼ˆæ·»åŠ è¾¹æ¥å¢å¼ºéŸ§æ€§ï¼‰"""
    samples = []
    
    # æ¨¡æ‹Ÿæ“ä½œåºåˆ—
    for step in range(budget):
        if env.graph.number_of_nodes() < 3:
            break
        
        # è·å–å€™é€‰è¾¹ï¼ˆä½¿ç”¨ç¯å¢ƒçš„å‰ªææ–¹æ³•ï¼‰
        candidate_edges = env.prune_candidates(candidate_type="edge", top_k=5)
        
        if not candidate_edges:
            break
        
        # è®¡ç®—æ·»åŠ è¾¹çš„å¢ç›Šåˆ†æ•°
        edge_gains = metrics.batch_compute_edge_gains(env.graph, candidate_edges)
        
        # æ„å»ºæ“ä½œå’Œæ ‡ç­¾
        auxiliary_labels = {}
        operations = []
        for idx, edge in enumerate(candidate_edges):
            op_id = f"op_{idx+1:02d}"
            score = edge_gains.get(edge, 0)
            if score < 0:
                score = 0
            auxiliary_labels[op_id] = round(score, 4)
            operations.append({"op_id": op_id, "target": edge})
        
        # è·å–æ­£ç¡®æ’åº
        ground_truth = sorted(
            auxiliary_labels.items(),
            key=lambda x: x[1],
            reverse=True
        )
        ground_truth_ranking = [op_id for op_id, _ in ground_truth]
        
        # ç”Ÿæˆæ¨ç†è¿‡ç¨‹
        reasoning = generate_reasoning_trace_construct(
            candidate_edges, 
            auxiliary_labels, 
            ground_truth_ranking,
            env.graph,
            node_semantics
        )
        
        # æ„å»ºè‡ªå®šä¹‰çš„ OCG æ•°æ®ï¼ˆå› ä¸º construct æ˜¯è¾¹æ“ä½œï¼‰
        sample = build_construct_conversation_data(
            graph=env.graph,
            candidate_edges=candidate_edges,
            current_step=step + 1,
            total_steps=budget,
            node_semantics=node_semantics,
            ground_truth_ranking=ground_truth_ranking,
            auxiliary_labels=auxiliary_labels,
            reasoning_trace=reasoning
        )
        
        # æ›´æ–°æ ·æœ¬ ID å’Œå…ƒæ•°æ®
        graph_type_str = data_source if data_source != "generate" else "ba"
        sample["id"] = f"train_construct_{data_source}_{graph_idx:04d}_{step:02d}"
        sample["meta"]["graph_type"] = graph_type_str
        sample["meta"]["num_nodes"] = actual_num_nodes
        sample["meta"]["graph_idx"] = graph_idx
        sample["meta"]["data_source"] = data_source
        sample["meta"]["sign"] = +1  # ç¬¦å·å‡½æ•°ï¼šconstruct æ˜¯å¢å¤§éŸ§æ€§
        if graph_file:
            sample["meta"]["graph_file"] = str(graph_file.name)
        
        samples.append(sample)
        
        # æ‰§è¡Œæœ€ä½³æ“ä½œï¼ˆæ·»åŠ è¾¹ï¼‰
        if ground_truth_ranking and operations:
            best_op = ground_truth_ranking[0]
            best_edge = operations[int(best_op.split("_")[1]) - 1]["target"]
            u, v = best_edge
            if u in env.graph and v in env.graph:
                env.graph.add_edge(u, v)
        
        env.current_step += 1
    
    return samples


def build_construct_conversation_data(
    graph: nx.Graph,
    candidate_edges: List[Tuple],
    current_step: int,
    total_steps: int,
    node_semantics: Dict,
    ground_truth_ranking: List[str],
    auxiliary_labels: Dict[str, float],
    reasoning_trace: str
) -> Dict:
    """ä¸º construct ä»»åŠ¡æ„å»ºå¯¹è¯æ•°æ®"""
    import json
    
    # ç³»ç»Ÿæç¤ºï¼ˆå¼ºè°ƒè¿™æ˜¯ç»Ÿä¸€çš„éŸ§æ€§ä¼˜åŒ–ä»»åŠ¡ï¼‰
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªç½‘ç»œéŸ§æ€§ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡åˆ†æå±€éƒ¨å­å›¾ç»“æ„ï¼ˆOCGï¼‰"
        "å’ŒèŠ‚ç‚¹è¯­ä¹‰ï¼Œé€‰æ‹©èƒ½æœ€æ˜¾è‘—æ”¹å˜ç½‘ç»œéŸ§æ€§ç§¯åˆ† R_res çš„æ“ä½œã€‚"
        "æœ¬æ¬¡ä»»åŠ¡æ˜¯æ„é€ ä»»åŠ¡ï¼ˆÏƒ=+1ï¼‰ï¼šé€‰æ‹©æ·»åŠ åèƒ½æœ€å¤§åŒ–æå‡ç½‘ç»œéŸ§æ€§çš„è¾¹ã€‚"
    )
    
    # æ„å»ºç”¨æˆ·æç¤º
    user_prompt = f"ã€å½“å‰çŠ¶æ€ã€‘\næ­¥éª¤ï¼š{current_step} / {total_steps}\n"
    user_prompt += "ç›®æ ‡ï¼šæœ€å¤§åŒ–éŸ§æ€§ (Construct, Ïƒ=+1)\n\n"
    user_prompt += "ã€å€™é€‰è¾¹ä¿¡æ¯ã€‘\nä»¥ä¸‹æ˜¯å€™é€‰è¾¹åŠå…¶ç«¯ç‚¹çš„è¯­ä¹‰æ‘˜è¦ï¼š\n\n"
    
    for idx, edge in enumerate(candidate_edges, 1):
        u, v = edge
        sem_u = node_semantics.get(u, f"èŠ‚ç‚¹{u}")
        sem_v = node_semantics.get(v, f"èŠ‚ç‚¹{v}")
        deg_u = graph.degree(u) if u in graph else 0
        deg_v = graph.degree(v) if v in graph else 0
        
        user_prompt += f"{idx}. è¾¹ [{u} â€” {v}]:\n"
        user_prompt += f"   - ç«¯ç‚¹1 [{u}]: {sem_u}ï¼Œåº¦æ•° {deg_u}\n"
        user_prompt += f"   - ç«¯ç‚¹2 [{v}]: {sem_v}ï¼Œåº¦æ•° {deg_v}\n"
        user_prompt += f"   - è¿æ¥æ„ä¹‰ï¼šæ·»åŠ æ­¤è¾¹å¯å¢å¼ºä¸¤èŠ‚ç‚¹é—´çš„è¿é€šæ€§\n\n"
    
    user_prompt += "ã€å€™é€‰æ“ä½œåˆ—è¡¨ã€‘\n"
    for idx, edge in enumerate(candidate_edges, 1):
        u, v = edge
        user_prompt += f"- [op_{idx:02d}]: æ·»åŠ è¾¹ ({u}, {v})\n"
    
    user_prompt += "\nè¯·åˆ†æä¸Šè¿°é€‰é¡¹ï¼Œå¹¶æŒ‰æ¨èä¼˜å…ˆçº§æ’åºï¼ˆå¢ç›Šæœ€å¤§çš„ä¼˜å…ˆï¼‰ã€‚"
    
    # ç”Ÿæˆ Assistant å›å¤
    response = {
        "reasoning_trace": reasoning_trace,
        "ranked_list": ground_truth_ranking,
        "best_action": ground_truth_ranking[0] if ground_truth_ranking else ""
    }
    assistant_content = f"```json\n{json.dumps(response, ensure_ascii=False, indent=2)}\n```"
    
    return {
        "id": f"train_construct_{current_step:03d}",
        "meta": {
            "task": "construct",
            "budget_step": f"{current_step}/{total_steps}"
        },
        "conversations": [
            {"from": "system", "value": system_prompt},
            {"from": "user", "value": user_prompt},
            {"from": "assistant", "value": assistant_content}
        ],
        "auxiliary_labels": auxiliary_labels
    }


def generate_reasoning_trace(
    candidates: List,
    auxiliary_labels: Dict[str, float],
    ground_truth_ranking: List[str],
    graph,
    node_semantics: Dict
) -> str:
    """ç”Ÿæˆæ¨ç†è¿‡ç¨‹æ–‡æœ¬ï¼ˆå…¼å®¹æ—§ä»£ç ï¼Œé»˜è®¤è°ƒç”¨ dismantleï¼‰"""
    return generate_reasoning_trace_dismantle(
        candidates, auxiliary_labels, ground_truth_ranking, graph, node_semantics
    )


def generate_reasoning_trace_dismantle(
    candidates: List,
    auxiliary_labels: Dict[str, float],
    ground_truth_ranking: List[str],
    graph,
    node_semantics: Dict
) -> str:
    """ç”Ÿæˆ dismantle ä»»åŠ¡çš„æ¨ç†è¿‡ç¨‹æ–‡æœ¬"""
    import networkx as nx
    
    reasoning_parts = []
    
    for rank, op_id in enumerate(ground_truth_ranking[:3], 1):
        idx = int(op_id.split("_")[1]) - 1
        if idx >= len(candidates):
            continue
        
        node = candidates[idx]
        score = auxiliary_labels[op_id]
        degree = graph.degree(node)
        semantic = node_semantics.get(node, "æœªçŸ¥")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å‰²ç‚¹
        is_articulation = node in set(nx.articulation_points(graph)) if nx.is_connected(graph) else False
        
        reason = f"{rank}. åˆ†æ [{op_id}] (ç§»é™¤èŠ‚ç‚¹ {node}): "
        reason += f"è¯¥èŠ‚ç‚¹æ˜¯'{semantic}'ï¼Œ"
        reason += f"åº¦æ•°ä¸º {degree}"
        if degree > len(candidates):
            reason += " (é«˜åº¦æ•°)"
        
        if is_articulation:
            reason += "ï¼Œæ˜¯ç½‘ç»œçš„å‰²ç‚¹ï¼Œç§»é™¤ä¼šå¯¼è‡´ç½‘ç»œåˆ†è£‚"
        
        if score > 0.5:
            reason += f"ã€‚é¢„è®¡ç ´ååˆ†æ•° {score:.2f}ï¼Œç ´ååŠ›è¾ƒå¤§ã€‚"
        elif score > 0.2:
            reason += f"ã€‚é¢„è®¡ç ´ååˆ†æ•° {score:.2f}ï¼Œæœ‰ä¸€å®šç ´ååŠ›ã€‚"
        else:
            reason += f"ã€‚é¢„è®¡ç ´ååˆ†æ•° {score:.2f}ï¼Œå½±å“æœ‰é™ã€‚"
        
        reasoning_parts.append(reason)
    
    return "\n".join(reasoning_parts)


def generate_reasoning_trace_construct(
    candidate_edges: List[Tuple],
    auxiliary_labels: Dict[str, float],
    ground_truth_ranking: List[str],
    graph,
    node_semantics: Dict
) -> str:
    """ç”Ÿæˆ construct ä»»åŠ¡çš„æ¨ç†è¿‡ç¨‹æ–‡æœ¬ï¼ˆæ·»åŠ è¾¹ï¼‰"""
    import networkx as nx
    
    reasoning_parts = []
    
    for rank, op_id in enumerate(ground_truth_ranking[:3], 1):
        idx = int(op_id.split("_")[1]) - 1
        if idx >= len(candidate_edges):
            continue
        
        edge = candidate_edges[idx]
        u, v = edge
        score = auxiliary_labels[op_id]
        
        # è·å–ç«¯ç‚¹ä¿¡æ¯
        deg_u = graph.degree(u) if u in graph else 0
        deg_v = graph.degree(v) if v in graph else 0
        sem_u = node_semantics.get(u, f"èŠ‚ç‚¹{u}")
        sem_v = node_semantics.get(v, f"èŠ‚ç‚¹{v}")
        
        reason = f"{rank}. åˆ†æ [{op_id}] (æ·»åŠ è¾¹ {u}-{v}): "
        reason += f"è¿æ¥'{sem_u}'(åº¦{deg_u}) ä¸ '{sem_v}'(åº¦{deg_v})"
        
        # åˆ†æè¿æ¥çš„æ„ä¹‰
        if deg_u < 3 or deg_v < 3:
            reason += "ï¼Œå¯å¢å¼ºä½åº¦æ•°èŠ‚ç‚¹çš„å†—ä½™è¿æ¥"
        elif deg_u > 5 and deg_v > 5:
            reason += "ï¼Œè¿æ¥ä¸¤ä¸ªæ ¸å¿ƒèŠ‚ç‚¹ï¼Œå¢å¼ºéª¨å¹²éŸ§æ€§"
        else:
            reason += "ï¼Œå¹³è¡¡ç½‘ç»œç»“æ„"
        
        if score > 0.1:
            reason += f"ã€‚é¢„è®¡å¢ç›Šåˆ†æ•° {score:.4f}ï¼Œå¢ç›Šæ˜¾è‘—ã€‚"
        elif score > 0.01:
            reason += f"ã€‚é¢„è®¡å¢ç›Šåˆ†æ•° {score:.4f}ï¼Œæœ‰ä¸€å®šå¢ç›Šã€‚"
        else:
            reason += f"ã€‚é¢„è®¡å¢ç›Šåˆ†æ•° {score:.4f}ï¼Œå¢ç›Šè¾ƒå°ã€‚"
        
        reasoning_parts.append(reason)
    
    return "\n".join(reasoning_parts)


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆç½‘ç»œéŸ§æ€§ä¼˜åŒ–è®­ç»ƒæ•°æ®")
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    parser.add_argument("--quick_test", action="store_true",
                        help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿè·‘é€šæµç¨‹")
    
    parser.add_argument("--data_source", type=str, default="generate", 
                        choices=["generate", "syn", "true", "all"],
                        help="æ•°æ®æ¥æº: generate(ç”ŸæˆBA/ER), syn(åˆæˆç½‘ç»œ), true(çœŸå®ç½‘ç»œ), all(æ··åˆ)")
    parser.add_argument("--raw_graphs_dir", type=str, default="data/raw_graphs",
                        help="åŸå§‹å›¾æ•°æ®ç›®å½•")
    parser.add_argument("--num_graphs", type=int, default=100, 
                        help="ä½¿ç”¨çš„å›¾æ•°é‡ï¼ˆå¯¹äºæ–‡ä»¶æ•°æ®ï¼Œä¼šéšæœºé‡‡æ ·ï¼‰")
    parser.add_argument("--graph_type", type=str, default="ba", 
                        choices=["ba", "er", "mixed"],
                        help="å›¾ç±»å‹ï¼ˆä»…åœ¨ data_source=generate æ—¶æœ‰æ•ˆï¼‰")
    parser.add_argument("--min_nodes", type=int, default=50, 
                        help="æœ€å°èŠ‚ç‚¹æ•°ï¼ˆä»…åœ¨ data_source=generate æ—¶æœ‰æ•ˆï¼‰")
    parser.add_argument("--max_nodes", type=int, default=200, 
                        help="æœ€å¤§èŠ‚ç‚¹æ•°ï¼ˆä»…åœ¨ data_source=generate æ—¶æœ‰æ•ˆï¼‰")
    parser.add_argument("--task_type", type=str, default="dismantle", 
                        choices=["dismantle", "construct", "both"], 
                        help="ä»»åŠ¡ç±»å‹")
    parser.add_argument("--budget", type=int, default=10, 
                        help="æ¯ä¸ªå›¾çš„æ“ä½œé¢„ç®—")
    parser.add_argument("--output_dir", type=str, default="data/fine_tuning", 
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--split_ratio", type=float, default=0.9, 
                        help="è®­ç»ƒé›†æ¯”ä¾‹")
    parser.add_argument("--min_graph_size", type=int, default=20,
                        help="æœ€å°å›¾å¤§å°ï¼ˆèŠ‚ç‚¹æ•°ï¼‰ï¼Œå°äºæ­¤å¤§å°çš„å›¾ä¼šè¢«è·³è¿‡")
    
    args = parser.parse_args()
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šè¦†ç›–å‚æ•°ä¸ºå°è§„æ¨¡
    if args.quick_test:
        print("=" * 60)
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿè·‘é€šæµç¨‹")
        print("=" * 60)
        args.num_graphs = 5  # åªç”¨ 5 ä¸ªå›¾
        args.budget = 3  # æ¯ä¸ªå›¾åªç”Ÿæˆ 3 æ­¥æ•°æ®
        args.min_nodes = 30
        args.max_nodes = 50
        args.task_type = "both"  # æ··åˆç”Ÿæˆ dismantle å’Œ construct
        args.output_dir = "data/fine_tuning/quick_test"
        args.data_source = "generate"  # ç›´æ¥ç”Ÿæˆå›¾
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    raw_graphs_dir = Path(args.raw_graphs_dir)
    
    print(f"Generating data with config:")
    print(f"  - Data source: {args.data_source}")
    print(f"  - Num graphs: {args.num_graphs}")
    print(f"  - Task type: {args.task_type}")
    print(f"  - Budget: {args.budget}")
    print(f"  - Output dir: {output_dir}")
    if args.data_source == "generate":
        print(f"  - Graph type: {args.graph_type}")
        print(f"  - Nodes range: [{args.min_nodes}, {args.max_nodes}]")
    
    all_samples = []
    
    # ç¡®å®šä»»åŠ¡ç±»å‹
    if args.task_type == "both":
        tasks = ["dismantle", "construct"]
    else:
        tasks = [args.task_type]
    
    # å‡†å¤‡å›¾åˆ—è¡¨
    graphs_to_process = []
    
    if args.data_source == "generate":
        # ç”Ÿæˆå›¾æ¨¡å¼
        if args.graph_type == "mixed":
            graph_types = ["ba", "er"]
        else:
            graph_types = [args.graph_type]
        
        for i in range(args.num_graphs):
            num_nodes = random.randint(args.min_nodes, args.max_nodes)
            graph_type = random.choice(graph_types)
            graphs_to_process.append(("generate", None, graph_type, num_nodes, None))
    else:
        # ä»æ–‡ä»¶åŠ è½½æ¨¡å¼
        graph_files = get_graph_files(args.data_source, raw_graphs_dir)
        
        if not graph_files:
            print(f"Error: No graph files found in {raw_graphs_dir}")
            print(f"Please check that {args.data_source} directory exists and contains .gml or .graphml files")
            return
        
        print(f"Found {len(graph_files)} graph files")
        
        # éšæœºé‡‡æ ·
        if len(graph_files) > args.num_graphs:
            graph_files = random.sample(graph_files, args.num_graphs)
        
        for graph_file, source_type in graph_files:
            graphs_to_process.append((source_type, graph_file, None, None, graph_file))
    
    # å¤„ç†æ‰€æœ‰å›¾
    total_graphs = len(graphs_to_process)
    successful = 0
    failed = 0
    
    for i, (data_source, graph_file, graph_type, num_nodes, file_path) in enumerate(graphs_to_process):
        task_type = random.choice(tasks)
        semantic_type = random.choice(["network", "infra", "generic"])
        
        try:
            # åŠ è½½æˆ–ç”Ÿæˆå›¾
            if data_source == "generate":
                graph = None
                print(f"[{i+1}/{total_graphs}] Generating {graph_type} graph with {num_nodes} nodes, task={task_type}")
            else:
                print(f"[{i+1}/{total_graphs}] Loading graph from {graph_file.name}, task={task_type}")
                graph = load_graph_from_file(graph_file)
                if graph is None:
                    failed += 1
                    continue
                
                actual_nodes = graph.number_of_nodes()
                if actual_nodes < args.min_graph_size:
                    print(f"  Skipped: graph too small ({actual_nodes} nodes < {args.min_graph_size})")
                    failed += 1
                    continue
            
            # ç”Ÿæˆè®­ç»ƒæ•°æ®
            samples = generate_single_graph_data(
                graph=graph,
                graph_type=graph_type,
                num_nodes=num_nodes,
                task_type=task_type,
                budget=args.budget,
                graph_idx=i,
                graph_file=graph_file if data_source != "generate" else None,
                data_source=data_source,
                semantic_type=semantic_type
            )
            
            all_samples.extend(samples)
            successful += 1
            print(f"  Generated {len(samples)} samples")
        except Exception as e:
            print(f"  Error: {e}")
            import traceback
            traceback.print_exc()
            failed += 1
            continue
    
    print(f"\nProcessing completed: {successful} successful, {failed} failed")
    
    print(f"\nTotal samples generated: {len(all_samples)}")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    random.shuffle(all_samples)
    split_idx = int(len(all_samples) * args.split_ratio)
    train_samples = all_samples[:split_idx]
    eval_samples = all_samples[split_idx:]
    
    # ä¿å­˜æ•°æ®
    train_path = output_dir / "train.json"
    eval_path = output_dir / "eval.json"
    
    with open(train_path, 'w', encoding='utf-8') as f:
        json.dump(train_samples, f, ensure_ascii=False, indent=2)
    print(f"Saved {len(train_samples)} training samples to {train_path}")
    
    with open(eval_path, 'w', encoding='utf-8') as f:
        json.dump(eval_samples, f, ensure_ascii=False, indent=2)
    print(f"Saved {len(eval_samples)} evaluation samples to {eval_path}")
    
    # ä¿å­˜é…ç½®
    config = {
        "data_source": args.data_source,
        "num_graphs": args.num_graphs,
        "task_type": args.task_type,
        "budget": args.budget,
        "seed": args.seed,
        "total_samples": len(all_samples),
        "train_samples": len(train_samples),
        "eval_samples": len(eval_samples),
        "successful_graphs": successful,
        "failed_graphs": failed
    }
    
    if args.data_source == "generate":
        config["graph_type"] = args.graph_type
        config["min_nodes"] = args.min_nodes
        config["max_nodes"] = args.max_nodes
    else:
        config["raw_graphs_dir"] = str(args.raw_graphs_dir)
        config["min_graph_size"] = args.min_graph_size
    
    config_path = output_dir / "data_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2)
    
    print(f"\nData generation completed!")
    print(f"Config saved to {config_path}")


if __name__ == "__main__":
    main()

# -*- coding: utf-8 -*-
"""
ResilienceTrainer: æ¨¡å‹è®­ç»ƒå™¨
è´Ÿè´£å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ LoRA å¾®è°ƒå’Œ ListMLE æ’åºå­¦ä¹ ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¸¤é˜¶æ®µè®­ç»ƒæ”¯æŒ (Phase 1: LLM only, Phase 2: Joint)
2. ListMLE æ’åºæŸå¤±è®­ç»ƒ
3. è®­ç»ƒçŠ¶æ€ç®¡ç†å’Œæ£€æŸ¥ç‚¹
4. è¯„ä¼°æŒ‡æ ‡è®¡ç®—
"""

from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from pathlib import Path
from dataclasses import dataclass, field
import json
import time
import logging
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR
from tqdm import tqdm


@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    # åŸºç¡€é…ç½®
    output_dir: str = "outputs"
    experiment_name: str = "resilience_llm"
    seed: int = 42
    
    # è®­ç»ƒè¶…å‚æ•°
    num_epochs: int = 3
    batch_size: int = 4
    gradient_accumulation_steps: int = 4
    learning_rate: float = 2e-5
    weight_decay: float = 0.01
    warmup_ratio: float = 0.1
    max_grad_norm: float = 1.0
    
    # æ’åºæŸå¤±é…ç½®
    ranking_loss_type: str = "listmle"  # "listmle", "listnet", "combined"
    ranking_loss_weight: float = 1.0
    lm_loss_weight: float = 0.5
    
    # è®­ç»ƒé˜¶æ®µ
    phase: int = 1  # 1: LLM only, 2: Joint
    freeze_llm_in_phase2: bool = False
    
    # è¯„ä¼°é…ç½®
    eval_steps: int = 100
    save_steps: int = 500
    logging_steps: int = 10
    
    # è®¾å¤‡é…ç½®
    device: str = "cuda"
    fp16: bool = True
    bf16: bool = False
    
    # å…¶ä»–
    resume_from_checkpoint: Optional[str] = None
    max_samples: Optional[int] = None  # ç”¨äºè°ƒè¯•


@dataclass
class TrainingState:
    """è®­ç»ƒçŠ¶æ€"""
    global_step: int = 0
    epoch: int = 0
    best_metric: float = 0.0
    train_loss_history: List[float] = field(default_factory=list)
    eval_metrics_history: List[Dict] = field(default_factory=list)


class ResilienceTrainer:
    """
    ç½‘ç»œéŸ§æ€§ä¼˜åŒ–æ¨¡å‹è®­ç»ƒå™¨
    
    æ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒï¼š
    - Phase 1: ä»…è®­ç»ƒ LLM (LoRA å‚æ•°)ï¼Œä½¿ç”¨æ ‡å‡† LM æŸå¤± + ListMLE
    - Phase 2: è”åˆè®­ç»ƒ LLM + GNN + Fusionï¼Œä½¿ç”¨ ListMLE æ’åºæŸå¤±
    
    è®­ç»ƒæµç¨‹ï¼š
    1. åŠ è½½æ•°æ®å’Œæ¨¡å‹
    2. é…ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    3. è®­ç»ƒå¾ªç¯
    4. è¯„ä¼°å’Œä¿å­˜æ£€æŸ¥ç‚¹
    
    Attributes:
        config: è®­ç»ƒé…ç½®
        model: æ¨¡å‹å®ä¾‹
        train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        eval_dataloader: è¯„ä¼°æ•°æ®åŠ è½½å™¨
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        state: è®­ç»ƒçŠ¶æ€
    """
    
    def __init__(
        self,
        model: nn.Module,
        train_dataloader: DataLoader,
        eval_dataloader: Optional[DataLoader] = None,
        config: Optional[TrainingConfig] = None
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: å¾…è®­ç»ƒæ¨¡å‹
            train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            eval_dataloader: è¯„ä¼°æ•°æ®åŠ è½½å™¨
            config: è®­ç»ƒé…ç½®
        """
        self.model = model
        self.train_dataloader = train_dataloader
        self.eval_dataloader = eval_dataloader
        self.config = config or TrainingConfig()
        
        self.state = TrainingState()
        self.optimizer = None
        self.scheduler = None
        self.loss_fn = None
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_dir = Path(self.config.output_dir) / self.config.experiment_name
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_training()
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(self.output_dir / "training.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _setup_training(self) -> None:
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device(self.config.device)
        self.model.to(self.device)
        
        # è®¾ç½®æŸå¤±å‡½æ•°
        from ..model.loss import create_ranking_loss
        self.loss_fn = create_ranking_loss(
            loss_type=self.config.ranking_loss_type
        )
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        self._setup_optimizer()
        
        # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
        self._setup_scheduler()
        
        # æ··åˆç²¾åº¦è®­ç»ƒé…ç½®
        # æ³¨æ„ï¼šç”±äºè‡ªå®šä¹‰æ’åºæŸå¤±å’Œ scoring_head çš„å¤æ‚æ€§ï¼ŒAMP + GradScaler ç»„åˆ
        # å®¹æ˜“äº§ç”Ÿ FP16 æ¢¯åº¦é—®é¢˜ï¼Œå› æ­¤é»˜è®¤ç¦ç”¨ GradScalerï¼Œä»…ä½¿ç”¨ autocast åŠ é€Ÿè®¡ç®—
        self.scaler = None
        self.use_amp = False  # æ˜¯å¦ä½¿ç”¨ autocast
        self.use_scaler = False  # æ˜¯å¦ä½¿ç”¨ GradScaler
        
        if self.config.fp16 or self.config.bf16:
            # æ£€æŸ¥æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹
            param_dtypes = set()
            for name, param in self.model.named_parameters():
                param_dtypes.add(param.dtype)
            
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç±»å‹: {param_dtypes}")
            
            # æ— è®ºæ¨¡å‹æ˜¯ä»€ä¹ˆç²¾åº¦ï¼Œéƒ½åªä½¿ç”¨ autocast è€Œä¸ä½¿ç”¨ GradScaler
            # è¿™æ ·å¯ä»¥è·å¾—è®¡ç®—åŠ é€Ÿï¼ŒåŒæ—¶é¿å…æ¢¯åº¦ç²¾åº¦é—®é¢˜
            print("âœ…  å¯ç”¨ autocast æ··åˆç²¾åº¦è®¡ç®—ï¼ˆä¸ä½¿ç”¨ GradScaler ä»¥é¿å…æ¢¯åº¦é—®é¢˜ï¼‰")
            self.use_amp = True
            self.use_scaler = False
            self.scaler = None
        else:
            print("â„¹ï¸  ä½¿ç”¨ FP32 å…¨ç²¾åº¦è®­ç»ƒ")
    
    def _setup_optimizer(self) -> None:
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        # æ”¶é›†éœ€è¦ä¼˜åŒ–çš„å‚æ•°
        if self.config.phase == 1:
            # Phase 1: ä»…ä¼˜åŒ– LoRA å‚æ•°
            params = [p for p in self.model.parameters() if p.requires_grad]
        else:
            # Phase 2: ä¼˜åŒ–æ‰€æœ‰å‚æ•°æˆ–å†»ç»“ LLM
            if self.config.freeze_llm_in_phase2:
                # å†»ç»“ LLMï¼Œåªä¼˜åŒ– GNN å’Œ Fusion
                params = []
                for name, param in self.model.named_parameters():
                    if "llm" not in name.lower() or "lora" in name.lower():
                        params.append(param)
            else:
                params = [p for p in self.model.parameters() if p.requires_grad]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯è®­ç»ƒå‚æ•°
        if len(params) == 0:
            error_msg = (
                "No trainable parameters found!\n"
                "This usually means the model has not been initialized properly.\n"
                "Please ensure:\n"
                "1. model.initialize(device) has been called\n"
                "2. _load_llm() and _apply_lora() methods are implemented\n"
                "3. Check src/model/fusion_llm.py and docs/training_setup_guide.md"
            )
            raise ValueError(error_msg)
        
        self.optimizer = AdamW(
            params,
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )
    
    def _setup_scheduler(self) -> None:
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        num_training_steps = (
            len(self.train_dataloader) * self.config.num_epochs 
            // self.config.gradient_accumulation_steps
        )
        num_warmup_steps = int(num_training_steps * self.config.warmup_ratio)
        
        # Warmup + Cosine Annealing
        warmup_scheduler = LinearLR(
            self.optimizer,
            start_factor=0.1,
            end_factor=1.0,
            total_iters=num_warmup_steps
        )
        
        cosine_scheduler = CosineAnnealingLR(
            self.optimizer,
            T_max=num_training_steps - num_warmup_steps,
            eta_min=1e-7
        )
        
        self.scheduler = torch.optim.lr_scheduler.SequentialLR(
            self.optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[num_warmup_steps]
        )
    
    def train(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œè®­ç»ƒ
        
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        self.logger.info(f"Starting training - Phase {self.config.phase}")
        self.logger.info(f"Config: {self.config}")
        
        # æ¢å¤æ£€æŸ¥ç‚¹
        if self.config.resume_from_checkpoint:
            self._load_checkpoint(self.config.resume_from_checkpoint)
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.state.epoch, self.config.num_epochs):
            self.state.epoch = epoch
            epoch_loss = self._train_epoch()
            
            self.logger.info(f"Epoch {epoch + 1}/{self.config.num_epochs} - Loss: {epoch_loss:.4f}")
            
            # è¯„ä¼°
            if self.eval_dataloader is not None:
                eval_metrics = self.evaluate()
                self.state.eval_metrics_history.append(eval_metrics)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if eval_metrics.get("ndcg", 0) > self.state.best_metric:
                    self.state.best_metric = eval_metrics["ndcg"]
                    self._save_checkpoint("best")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            self._save_checkpoint(f"epoch_{epoch + 1}")
        
        self.logger.info("Training completed!")
        return {
            "final_loss": self.state.train_loss_history[-1] if self.state.train_loss_history else 0,
            "best_metric": self.state.best_metric,
            "total_steps": self.state.global_step
        }
    
    def _train_epoch(self) -> float:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        progress_bar = tqdm(
            self.train_dataloader,
            desc=f"Epoch {self.state.epoch + 1}",
            leave=True
        )
        
        self.optimizer.zero_grad()
        
        for batch_idx, batch in enumerate(progress_bar):
            # å‰å‘ä¼ æ’­
            loss = self._training_step(batch)
            
            # æ¢¯åº¦ç´¯ç§¯
            loss = loss / self.config.gradient_accumulation_steps
            
            # ç¡®ä¿æŸå¤±æ˜¯ FP32ï¼Œé¿å… FP16 æ¢¯åº¦é—®é¢˜
            if loss.dtype != torch.float32:
                loss = loss.float()
            
            # NaN/Inf æ£€æŸ¥ï¼šè·³è¿‡æ— æ•ˆçš„æ‰¹æ¬¡
            loss_value = loss.item()
            if not (loss_value == loss_value) or loss_value == float('inf') or loss_value == float('-inf'):
                # loss_value != loss_value æ˜¯æ£€æµ‹ NaN çš„æŠ€å·§
                self.logger.warning(f"è·³è¿‡æ‰¹æ¬¡ {batch_idx}ï¼šæŸå¤±ä¸º NaN æˆ– Inf")
                self.optimizer.zero_grad()  # æ¸…é™¤å¯èƒ½çš„æ— æ•ˆæ¢¯åº¦
                continue
            
            # åå‘ä¼ æ’­
            if self.use_scaler and self.scaler is not None:
                # FP32 æ¨¡å‹ + AMP + GradScalerï¼šä½¿ç”¨ scaled backward
                self.scaler.scale(loss).backward()
            else:
                # æ—  GradScalerï¼šç›´æ¥åå‘ä¼ æ’­
                loss.backward()
            
            total_loss += loss_value * self.config.gradient_accumulation_steps
            num_batches += 1
            
            # æ¢¯åº¦æ›´æ–°
            if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0:
                if self.use_scaler and self.scaler is not None:
                    # FP32 + AMP çš„æ¢¯åº¦æ›´æ–°æµç¨‹
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.config.max_grad_norm
                    )
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    # åŸç”Ÿ FP16 æˆ–çº¯ FP32ï¼šç›´æ¥æ›´æ–°
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.config.max_grad_norm
                    )
                    self.optimizer.step()
                
                self.scheduler.step()
                self.optimizer.zero_grad()
                self.state.global_step += 1
                
                # æ—¥å¿—
                if self.state.global_step % self.config.logging_steps == 0:
                    avg_loss = total_loss / num_batches
                    lr = self.optimizer.param_groups[0]['lr']
                    progress_bar.set_postfix({
                        "loss": f"{avg_loss:.4f}",
                        "lr": f"{lr:.2e}"
                    })
                
                # ä¸­é—´è¯„ä¼°
                if (self.eval_dataloader is not None and 
                    self.state.global_step % self.config.eval_steps == 0):
                    eval_metrics = self.evaluate()
                    self.model.train()
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if self.state.global_step % self.config.save_steps == 0:
                    self._save_checkpoint(f"step_{self.state.global_step}")
        
        epoch_loss = total_loss / max(num_batches, 1)
        self.state.train_loss_history.append(epoch_loss)
        
        return epoch_loss
    
    def _training_step(self, batch: Dict) -> torch.Tensor:
        """
        å•æ­¥è®­ç»ƒ
        
        Args:
            batch: æ‰¹æ¬¡æ•°æ®
        
        Returns:
            loss: æŸå¤±å€¼
        """
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        input_ids = batch.get("input_ids")
        attention_mask = batch.get("attention_mask")
        labels = batch.get("labels")
        auxiliary_labels = batch["auxiliary_labels"].to(self.device)
        candidate_mask = batch.get("candidate_mask")
        if candidate_mask is not None:
            candidate_mask = candidate_mask.to(self.device)
        
        # æ··åˆç²¾åº¦ï¼ˆåªåœ¨ use_amp=True æ—¶å¯ç”¨ï¼‰
        with torch.amp.autocast(device_type='cuda' if self.device.type == 'cuda' else 'cpu', enabled=self.use_amp):
            # æ¨¡å‹å‰å‘ä¼ æ’­
            if input_ids is not None:
                input_ids = input_ids.to(self.device)
                attention_mask = attention_mask.to(self.device)
                
                # è·å–å€™é€‰æ“ä½œä½ç½®ç´¢å¼•ï¼ˆä» prompt ä¸­æå–æˆ–ä½¿ç”¨ç®€åŒ–æ–¹æ³•ï¼‰
                candidate_indices = self._extract_candidate_indices(batch, input_ids)
                
                outputs = self.model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    candidate_indices=candidate_indices,
                    return_scores=True
                )
                
                # LM æŸå¤±
                if labels is not None and self.config.lm_loss_weight > 0:
                    labels = labels.to(self.device)
                    lm_loss = self._compute_lm_loss(outputs["logits"], labels)
                else:
                    lm_loss = 0.0
                
                # æ’åºæŸå¤±
                if "scores" in outputs and outputs["scores"] is not None:
                    ranking_loss = self.loss_fn(
                        outputs["scores"],
                        auxiliary_labels,
                        mask=candidate_mask
                    )
                else:
                    # å¦‚æœæ²¡æœ‰ scoresï¼Œä½¿ç”¨ hidden states è®¡ç®—
                    hidden_states = outputs.get("hidden_states")
                    ranking_loss = self._compute_ranking_loss_from_hidden_states(
                        hidden_states,
                        outputs["logits"],
                        auxiliary_labels,
                        candidate_mask,
                        attention_mask
                    )
            else:
                # å¦‚æœæ²¡æœ‰ input_idsï¼Œè¯´æ˜æ•°æ®åŠ è½½æœ‰é—®é¢˜
                raise ValueError(
                    "input_ids ä¸ºç©ºï¼è¯·ç¡®ä¿æ•°æ®åŠ è½½å™¨ä¼ å…¥äº† tokenizerã€‚"
                    "æ£€æŸ¥ scripts/train.py ä¸­ create_dataloader æ˜¯å¦ä¼ å…¥äº† tokenizer å‚æ•°ã€‚"
                )
            
            # æ€»æŸå¤±
            total_loss = (
                self.config.lm_loss_weight * lm_loss +
                self.config.ranking_loss_weight * ranking_loss
            )
            
            # NaN æ£€æŸ¥å’Œå¤„ç†
            if torch.isnan(total_loss) or torch.isinf(total_loss):
                # è®°å½•è­¦å‘Šä½†ä¸ä¸­æ–­è®­ç»ƒ
                self.logger.warning(f"æ£€æµ‹åˆ° NaN/Inf æŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡ (lm_loss={lm_loss}, ranking_loss={ranking_loss})")
                # è¿”å›ä¸€ä¸ªå°çš„æœ‰æ•ˆæŸå¤±å€¼ï¼Œé¿å…æ¢¯åº¦æ›´æ–°å‡ºé—®é¢˜
                total_loss = torch.tensor(0.0, device=self.device, requires_grad=True)
        
        return total_loss
    
    def _compute_lm_loss(
        self, 
        logits: torch.Tensor, 
        labels: torch.Tensor
    ) -> torch.Tensor:
        """è®¡ç®—è¯­è¨€æ¨¡å‹æŸå¤±"""
        # ç§»ä½ logits å’Œ labels
        shift_logits = logits[..., :-1, :].contiguous()
        shift_labels = labels[..., 1:].contiguous()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ labelsï¼ˆé -100ï¼‰
        valid_mask = (shift_labels != -100)
        num_valid = valid_mask.sum().item()
        
        if num_valid == 0:
            # æ²¡æœ‰æœ‰æ•ˆçš„ labelsï¼Œè¿”å› 0 æŸå¤±
            self.logger.debug("LM æŸå¤±è®¡ç®—ï¼šæ²¡æœ‰æœ‰æ•ˆçš„ labelsï¼Œè·³è¿‡")
            return torch.tensor(0.0, device=logits.device, dtype=logits.dtype)
        
        # æ£€æŸ¥ logits æ˜¯å¦åŒ…å« NaN/Inf
        if torch.isnan(shift_logits).any() or torch.isinf(shift_logits).any():
            self.logger.warning("LM æŸå¤±è®¡ç®—ï¼šlogits åŒ…å« NaN/Inf")
            return torch.tensor(0.0, device=logits.device, dtype=logits.dtype)
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss_fct = nn.CrossEntropyLoss(ignore_index=-100)
        loss = loss_fct(
            shift_logits.view(-1, shift_logits.size(-1)),
            shift_labels.view(-1)
        )
        
        # æœ€ç»ˆ NaN æ£€æŸ¥
        if torch.isnan(loss) or torch.isinf(loss):
            self.logger.warning(f"LM æŸå¤±è®¡ç®—ç»“æœä¸º NaN/Inf (æœ‰æ•ˆæ ·æœ¬æ•°: {num_valid})")
            return torch.tensor(0.0, device=logits.device, dtype=logits.dtype)
        
        return loss
    
    def _extract_candidate_indices(
        self, 
        batch: Dict, 
        input_ids: torch.Tensor
    ) -> Optional[torch.Tensor]:
        """
        ä» batch ä¸­æå–å€™é€‰æ“ä½œåœ¨åºåˆ—ä¸­çš„ä½ç½®ç´¢å¼•
        
        ç®€åŒ–å®ç°ï¼šä½¿ç”¨åºåˆ—æœ«å°¾çš„ token ä½ç½®ä½œä¸ºå€™é€‰æ“ä½œçš„è¡¨ç¤ºä½ç½®
        æ›´ç²¾ç¡®çš„å®ç°éœ€è¦ä» prompt ä¸­è§£ææ“ä½œæè¿°çš„ä½ç½®
        
        Args:
            batch: æ‰¹æ¬¡æ•°æ®
            input_ids: Token IDs [batch_size, seq_len]
        
        Returns:
            candidate_indices: [batch_size, num_candidates] æˆ– None
        """
        batch_size, seq_len = input_ids.shape
        
        # ä» batch ä¸­è·å–å€™é€‰æ•°é‡
        auxiliary_labels = batch.get("auxiliary_labels")
        if auxiliary_labels is None:
            return None
        
        num_candidates = auxiliary_labels.shape[1] if isinstance(auxiliary_labels, torch.Tensor) else 0
        
        if num_candidates == 0:
            return None
        
        # ç®€åŒ–æ–¹æ³•ï¼šä½¿ç”¨åºåˆ—æœ«å°¾çš„ token ä½ç½®
        # å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä» prompt ä¸­è§£ææ“ä½œæè¿°çš„ä½ç½®
        # è¿™é‡Œä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆ token çš„ä½ç½®ï¼ˆè€ƒè™‘ paddingï¼‰
        candidate_indices = []
        attention_mask = batch.get("attention_mask", None)
        
        for i in range(batch_size):
            if attention_mask is not None:
                # ä½¿ç”¨ attention_mask æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆä½ç½®
                valid_length = attention_mask[i].sum().item()
                # ä½¿ç”¨æœ€åå‡ ä¸ªä½ç½®ä½œä¸ºå€™é€‰æ“ä½œçš„è¡¨ç¤º
                # ç®€åŒ–ï¼šæ¯ä¸ªå€™é€‰æ“ä½œä½¿ç”¨ä¸€ä¸ªä½ç½®
                positions = []
                for j in range(num_candidates):
                    # ä»æœ«å°¾å¾€å‰å–ä½ç½®
                    pos = max(0, valid_length - num_candidates + j)
                    positions.append(pos)
                candidate_indices.append(positions)
            else:
                # å¦‚æœæ²¡æœ‰ attention_maskï¼Œä½¿ç”¨åºåˆ—æœ«å°¾
                positions = [max(0, seq_len - num_candidates + j) for j in range(num_candidates)]
                candidate_indices.append(positions)
        
        return torch.tensor(candidate_indices, device=input_ids.device, dtype=torch.long)
    
    def _compute_ranking_loss_from_hidden_states(
        self,
        hidden_states: Optional[torch.Tensor],
        logits: torch.Tensor,
        auxiliary_labels: torch.Tensor,
        candidate_mask: Optional[torch.Tensor],
        attention_mask: torch.Tensor
    ) -> torch.Tensor:
        """
        ä» hidden states æˆ– logits è®¡ç®—æ’åºæŸå¤±ï¼ˆå½“æ¨¡å‹æ²¡æœ‰ç›´æ¥è¾“å‡º scores æ—¶ï¼‰
        
        ç®€åŒ–æ–¹æ³•ï¼šä½¿ç”¨åºåˆ—çš„å¹³å‡æ± åŒ–è¡¨ç¤ºæ¥è®¡ç®—åˆ†æ•°
        """
        batch_size, seq_len = logits.shape[:2]
        num_candidates = auxiliary_labels.shape[1]
        
        # å¦‚æœæœ‰ hidden_statesï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ logits
        if hidden_states is not None:
            # ä½¿ç”¨ hidden states çš„å¹³å‡æ± åŒ–
            if attention_mask is not None:
                # åŠ æƒå¹³å‡ï¼ˆåªè€ƒè™‘æœ‰æ•ˆ tokenï¼‰
                # ç¡®ä¿ attention_mask çš„æ•°æ®ç±»å‹ä¸ hidden_states ä¸€è‡´
                mask_expanded = attention_mask.unsqueeze(-1).to(hidden_states.dtype)  # [batch_size, seq_len, 1]
                masked_hidden = hidden_states * mask_expanded
                # ç¡®ä¿é™¤æ³•æ“ä½œçš„æ•°æ®ç±»å‹ä¸€è‡´
                sum_mask = attention_mask.sum(dim=1, keepdim=True).to(hidden_states.dtype).unsqueeze(-1)
                sum_mask = sum_mask.clamp(min=1.0)  # é˜²æ­¢é™¤ä»¥0
                pooled = masked_hidden.sum(dim=1) / sum_mask.squeeze(-1)
            else:
                pooled = hidden_states.mean(dim=1)  # [batch_size, hidden_dim]
            
            # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
            pooled = self.model._project_to_d_model(pooled.unsqueeze(1))  # [batch_size, 1, d_model]
            pooled = pooled.squeeze(1)  # [batch_size, d_model]
        else:
            # ä½¿ç”¨ logits çš„æœ€åä¸€ä¸ªä½ç½®ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰
            if attention_mask is not None:
                valid_lengths = attention_mask.sum(dim=1).long()  # [batch_size], ç¡®ä¿æ˜¯ long ç±»å‹
                last_logits = []
                for i in range(batch_size):
                    last_pos = max(0, valid_lengths[i].item() - 1)
                    last_logits.append(logits[i, last_pos, :])
                pooled = torch.stack(last_logits)  # [batch_size, vocab_size]
            else:
                pooled = logits[:, -1, :]  # [batch_size, vocab_size]
            
            # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
            if pooled.shape[1] != self.model.config.d_model:
                pooled = self.model._project_to_d_model(pooled.unsqueeze(1))
                pooled = pooled.squeeze(1)
        
        # æ‰©å±•åˆ°å€™é€‰æ•°é‡
        pooled = pooled.unsqueeze(1).expand(-1, num_candidates, -1)  # [batch_size, num_candidates, d_model]
        
        # ç¡®ä¿ scoring_head ä¸è¾“å…¥æ•°æ®ç±»å‹ä¸€è‡´
        if self.model.scoring_head[0].weight.dtype != pooled.dtype:
            self.model.scoring_head = self.model.scoring_head.to(pooled.dtype)
        if self.model.scoring_head[0].weight.device != pooled.device:
            self.model.scoring_head = self.model.scoring_head.to(pooled.device)
        
        # é€šè¿‡ scoring_head è®¡ç®—åˆ†æ•°
        scores = self.model.scoring_head(pooled).squeeze(-1)  # [batch_size, num_candidates]
        
        # è®¡ç®—æ’åºæŸå¤±
        ranking_loss = self.loss_fn(
            scores,
            auxiliary_labels,
            mask=candidate_mask
        )
        
        return ranking_loss
    
    def evaluate(self) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹
        
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        self.model.eval()
        
        all_scores = []
        all_labels = []
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(self.eval_dataloader, desc="Evaluating"):
                auxiliary_labels = batch["auxiliary_labels"].to(self.device).float()
                candidate_mask = batch["candidate_mask"].to(self.device).float()
                
                # è·å–æ¨¡å‹é¢„æµ‹
                input_ids = batch.get("input_ids")
                if input_ids is not None:
                    input_ids = input_ids.to(self.device)
                    attention_mask = batch["attention_mask"].to(self.device)
                    
                    # æå–å€™é€‰ç´¢å¼•
                    candidate_indices = self._extract_candidate_indices(batch, input_ids)
                    
                    # ç¦ç”¨æ··åˆç²¾åº¦ä»¥é¿å…æ•°æ®ç±»å‹é—®é¢˜
                    with torch.amp.autocast(device_type='cuda' if self.device.type == 'cuda' else 'cpu', enabled=False):
                        outputs = self.model(
                            input_ids=input_ids,
                            attention_mask=attention_mask,
                            candidate_indices=candidate_indices,
                            return_scores=True
                        )
                    
                    if "scores" in outputs and outputs["scores"] is not None:
                        scores = outputs["scores"]
                    else:
                        continue
                else:
                    continue
                
                # è®¡ç®—æŸå¤±
                loss = self.loss_fn(scores, auxiliary_labels, mask=candidate_mask)
                total_loss += loss.item()
                num_batches += 1
                
                # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾ï¼ˆç¡®ä¿è½¬æ¢ä¸º float å†ç§»åˆ° CPUï¼‰
                all_scores.append(scores.detach().cpu().float())
                all_labels.append(auxiliary_labels.detach().cpu().float())
        
        # è®¡ç®—æŒ‡æ ‡
        from ..model.loss import RankingMetrics
        
        all_scores = torch.cat(all_scores, dim=0)
        all_labels = torch.cat(all_labels, dim=0)
        
        metrics = {
            "loss": total_loss / max(num_batches, 1),
            "ndcg": 0.0,
            "mrr": 0.0,
            "precision_at_1": 0.0
        }
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æŒ‡æ ‡
        ndcg_list = []
        mrr_list = []
        p1_list = []
        
        for i in range(all_scores.shape[0]):
            ndcg_list.append(RankingMetrics.ndcg(all_scores[i], all_labels[i]))
            mrr_list.append(RankingMetrics.mrr(all_scores[i], all_labels[i]))
            p1_list.append(RankingMetrics.precision_at_k(all_scores[i], all_labels[i], k=1))
        
        metrics["ndcg"] = sum(ndcg_list) / len(ndcg_list)
        metrics["mrr"] = sum(mrr_list) / len(mrr_list)
        metrics["precision_at_1"] = sum(p1_list) / len(p1_list)
        
        self.logger.info(f"Evaluation - Loss: {metrics['loss']:.4f}, "
                        f"NDCG: {metrics['ndcg']:.4f}, "
                        f"MRR: {metrics['mrr']:.4f}, "
                        f"P@1: {metrics['precision_at_1']:.4f}")
        
        return metrics
    
    def _save_checkpoint(self, name: str) -> None:
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = self.output_dir / "checkpoints" / name
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        torch.save(self.model.state_dict(), checkpoint_dir / "model.pt")
        
        # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
        torch.save({
            "optimizer": self.optimizer.state_dict(),
            "scheduler": self.scheduler.state_dict(),
            "scaler": self.scaler.state_dict() if self.scaler else None
        }, checkpoint_dir / "optimizer.pt")
        
        # ä¿å­˜è®­ç»ƒçŠ¶æ€
        state_dict = {
            "global_step": self.state.global_step,
            "epoch": self.state.epoch,
            "best_metric": self.state.best_metric,
            "train_loss_history": self.state.train_loss_history,
            "eval_metrics_history": self.state.eval_metrics_history
        }
        with open(checkpoint_dir / "state.json", 'w') as f:
            json.dump(state_dict, f, indent=2)
        
        self.logger.info(f"Saved checkpoint to {checkpoint_dir}")
    
    def _load_checkpoint(self, checkpoint_path: str) -> None:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint_dir = Path(checkpoint_path)
        
        # åŠ è½½æ¨¡å‹
        model_path = checkpoint_dir / "model.pt"
        if model_path.exists():
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        optimizer_path = checkpoint_dir / "optimizer.pt"
        if optimizer_path.exists():
            opt_state = torch.load(optimizer_path, map_location=self.device)
            self.optimizer.load_state_dict(opt_state["optimizer"])
            self.scheduler.load_state_dict(opt_state["scheduler"])
            if self.scaler and opt_state.get("scaler"):
                self.scaler.load_state_dict(opt_state["scaler"])
        
        # åŠ è½½è®­ç»ƒçŠ¶æ€
        state_path = checkpoint_dir / "state.json"
        if state_path.exists():
            with open(state_path, 'r') as f:
                state_dict = json.load(f)
            self.state.global_step = state_dict["global_step"]
            self.state.epoch = state_dict["epoch"]
            self.state.best_metric = state_dict["best_metric"]
            self.state.train_loss_history = state_dict["train_loss_history"]
            self.state.eval_metrics_history = state_dict["eval_metrics_history"]
        
        self.logger.info(f"Loaded checkpoint from {checkpoint_dir}")


# ==================== ä¾¿æ·å‡½æ•° ====================

def train_resilience_model(
    model: nn.Module,
    train_data_path: str,
    eval_data_path: Optional[str] = None,
    output_dir: str = "outputs",
    **kwargs
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè®­ç»ƒéŸ§æ€§ä¼˜åŒ–æ¨¡å‹
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        train_data_path: è®­ç»ƒæ•°æ®è·¯å¾„
        eval_data_path: è¯„ä¼°æ•°æ®è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        **kwargs: è®­ç»ƒé…ç½®å‚æ•°
    
    Returns:
        è®­ç»ƒç»“æœ
    """
    from ..data.dataset import create_dataloader
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = create_dataloader(train_data_path, batch_size=kwargs.get("batch_size", 4))
    eval_loader = None
    if eval_data_path:
        eval_loader = create_dataloader(eval_data_path, batch_size=kwargs.get("batch_size", 4), shuffle=False)
    
    # åˆ›å»ºé…ç½®
    config = TrainingConfig(output_dir=output_dir, **kwargs)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ResilienceTrainer(
        model=model,
        train_dataloader=train_loader,
        eval_dataloader=eval_loader,
        config=config
    )
    
    # è®­ç»ƒ
    return trainer.train()
